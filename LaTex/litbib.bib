% This file was created with Citavi 6.12.0.0

@book{.,
 title = {Journal of Machine Learning Research 23}
}


@proceedings{.2013,
 year = {2013},
 title = {Proceedings of the Python in Science Conference},
 publisher = {SciPy},
 isbn = {2575-9752}
}


@proceedings{.2014,
 year = {2014},
 title = {Computer Science, Communication and Instrumentation Devices},
 address = {Singapore},
 publisher = {{Research Publishing Services}}
}


@proceedings{.2015,
 year = {2015},
 title = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 publisher = {IEEE}
}


@proceedings{.2016,
 year = {2016},
 title = {2016 10th International Conference on Sensing Technology (ICST)},
 publisher = {IEEE}
}


@proceedings{.2018,
 year = {2018},
 title = {2018 IEEE Symposium Series on Computational Intelligence (SSCI)},
 publisher = {IEEE}
}


@proceedings{.2018b,
 year = {2018},
 title = {2018 International Interdisciplinary PhD Workshop (IIPhDW)},
 publisher = {IEEE}
}


@proceedings{.2018c,
 year = {2018},
 title = {2018 International Interdisciplinary PhD Workshop (IIPhDW)},
 publisher = {IEEE}
}


@proceedings{.2018d,
 year = {2018},
 title = {2018 Chinese Control And Decision Conference (CCDC)},
 publisher = {IEEE}
}


@proceedings{.2019,
 year = {2019},
 title = {Proceedings of the International Conference on Artificial Intelligence, Information Processing and Cloud Computing},
 address = {New York, NY, USA},
 publisher = {ACM}
}


@proceedings{.2019b,
 year = {2019},
 title = {2019 Prognostics and System Health Management Conference (PHM-Paris)},
 publisher = {IEEE}
}


@book{.2019c,
 year = {2019},
 title = {Leichtbau-Konstruktion},
 publisher = {{Springer Vieweg, Wiesbaden}}
}


@proceedings{.2020,
 year = {2020},
 title = {2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)},
 publisher = {IEEE}
}


@book{.2020b,
 year = {2020},
 title = {Deep Learning: Algorithms and Applications},
 publisher = {{Springer, Cham}}
}


@proceedings{.2020c,
 year = {2020},
 title = {2020 IEEE Power {\&} Energy Society General Meeting (PESGM)},
 publisher = {IEEE}
}


@proceedings{.2020d,
 year = {2020},
 title = {2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM)},
 publisher = {IEEE}
}


@proceedings{.2021,
 year = {2021}
}


@book{.b,
 title = {2022 Journal of Machine Learning Research}
}


@misc{Activation,
 author = {{Gilbert Tanner}},
 year = {2023},
 title = {Activation Functions: Acces Date: 21.05.2023},
 url = {https://ml-explained.com/blog/activation-functions-explained}
}


@misc{Active,
 abstract = {{\textquotedbl} id=},
 year = {21/05/2023},
 title = {Activation Function},
 url = {https://machine-learning.paperspace.com/wiki/activation-function},
 urldate = {21/05/2023}
}


@article{Adasooriya,
 abstract = {Abstract A formula is proposed to predict fatigue strength of corroded members and joints of steel structures. The concept of the formula is first studied from recently identified mechanism of corr...},
 author = {Adasooriya, N. D. and Pavlou, D. and Hemmingsen, T.},
 year = {2020},
 title = {Fatigue strength degradation of corroded structural details: A formula for S--N curve},
 pages = {721--733},
 volume = {43},
 number = {4},
 issn = {8756-758X},
 journal = {Fatigue {\&} Fracture of Engineering Materials {\&} Structures},
 doi = {10.1111/ffe.13156},
 file = {Adasooriya, Pavlou et al. 2020 - Fatigue strength degradation of corroded:Attachments/Adasooriya, Pavlou et al. 2020 - Fatigue strength degradation of corroded.pdf:application/pdf}
}


@article{Ahsan,
 abstract = {Heart disease, one of the main reasons behind the high mortality rate around the world, requires a sophisticated and expensive diagnosis process. In the recent past, much literature has demonstrated machine learning approaches as an opportunity to efficiently diagnose heart disease patients. However, challenges associated with datasets such as missing data, inconsistent data, and mixed data (containing inconsistent missing data both as numerical and categorical) are often obstacles in medical diagnosis. This inconsistency led to a higher probability of misprediction and a misled result. Data preprocessing steps like feature reduction, data conversion, and data scaling are employed to form a standard dataset---such measures play a crucial role in reducing inaccuracy in final prediction. This paper aims to evaluate eleven machine learning (ML) algorithms---Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Naive Bayes (NB), Support Vector Machine (SVM), XGBoost (XGB), Random Forest Classifier (RF), Gradient Boost (GB), AdaBoost (AB), Extra Tree Classifier (ET)---and six different data scaling methods---Normalization (NR), Standscale (SS), MinMax (MM), MaxAbs (MA), Robust Scaler (RS), and Quantile Transformer (QT) on a dataset comprising of information of patients with heart disease. The result shows that CART, along with RS or QT, outperforms all other ML algorithms with 100{\%} accuracy, 100{\%} precision, 99{\%} recall, and 100{\%} F1 score. The study outcomes demonstrate that the model's performance varies depending on the data scaling method.},
 author = {Ahsan, Md and Mahmud, M. and Saha, Pritom and Gupta, Kishor and Siddique, Zahed},
 year = {2021},
 title = {Effect of Data Scaling Methods on Machine Learning Algorithms and Model Performance},
 url = {https://www.mdpi.com/2227-7080/9/3/52},
 pages = {52},
 volume = {9},
 number = {3},
 issn = {2227-7080},
 journal = {Technologies},
 doi = {10.3390/technologies9030052},
 file = {Ahsan, Mahmud et al. 2021 - Effect of Data Scaling Methods:Attachments/Ahsan, Mahmud et al. 2021 - Effect of Data Scaling Methods.pdf:application/pdf}
}


@article{Alzubaidi,
 abstract = {In the last few years, the deep learning (DL) computing paradigm has been deemed the Gold Standard in the machine learning (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of data. The DL field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, DL has outperformed well-known ML techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on DL, all of them only tackled one aspect of the DL, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of DL. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field. In particular, this paper outlines the importance of DL, presents the types of DL techniques and networks. It then presents convolutional neural networks (CNNs) which the most utilized DL network type and describes the development of CNNs architectures together with their main features, e.g., starting with the AlexNet network and closing with the High-Resolution network (HR.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major DL applications. Computational tools including FPGA, GPU, and CPU are summarized along with a description of their influence on DL. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.},
 author = {Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamar{\'i}a, J. and Fadhel, Mohammed A. and Al-Amidie, Muthana and Farhan, Laith},
 year = {2021},
 title = {Review of deep learning: concepts, CNN architectures, challenges, applications, future directions},
 keywords = {Convolution neural network (CNN);Deep Learning;Deep learning applications;Deep neural network architectures;FPGA;GPU;Image classification;Machine learning;Medical image analysis;Supervised learning;Transfer learning},
 pages = {53},
 volume = {8},
 number = {1},
 issn = {2196-1115},
 journal = {Journal of big data},
 doi = {10.1186/s40537-021-00444-8},
 file = {Alzubaidi, Zhang et al 2021 - Review of deep learning:Attachments/Alzubaidi, Zhang et al 2021 - Review of deep learning.pdf:application/pdf}
}


@book{Asadi,
 abstract = {In this paper, we have extended the well-established universal approximator theory to neural networks that use the unbounded ReLU activation function and a nonlinear softmax output layer. We have proved that a sufficiently large neural network using the ReLU activation function can approximate any function in {\$}L{\^{}}1{\$} up to any arbitrary precision. Moreover, our theoretical results have shown that a large enough neural network using a nonlinear softmax output layer can also approximate any indicator function in {\$}L{\^{}}1{\$}, which is equivalent to mutually-exclusive class labels in any realistic multiple-class pattern classification problems. To the best of our knowledge, this work is the first theoretical justification for using the softmax output layers in neural networks for pattern classification.},
 author = {Asadi, Behnam and Jiang, Hui},
 year = {2020},
 title = {On Approximation Capabilities of ReLU Activation and Softmax Output  Layer in Neural Networks},
 url = {http://arxiv.org/pdf/2002.04060v1},
 file = {Asadi, Jiang 10 02 2020 - On Approximation Capabilities of ReLU:Attachments/Asadi, Jiang 10 02 2020 - On Approximation Capabilities of ReLU.pdf:application/pdf}
}


@article{Baldominos,
 author = {Baldominos, Alejandro and Saez, Yago and Isasi, Pedro},
 year = {2019},
 title = {A Survey of Handwritten Character Recognition with MNIST and EMNIST},
 pages = {3169},
 volume = {9},
 number = {15},
 journal = {Applied Sciences},
 doi = {10.3390/app9153169},
 file = {Baldominos, Saez et al. 2019 - A Survey of Handwritten Character:Attachments/Baldominos, Saez et al. 2019 - A Survey of Handwritten Character.pdf:application/pdf}
}


@article{Bandara,
 author = {Bandara, Kasun and Hewamalage, Hansika and Liu, Yuan-Hao and Kang, Yanfei and Bergmeir, Christoph},
 year = {2021},
 title = {Improving the accuracy of global forecasting models using time series data augmentation},
 url = {https://www.sciencedirect.com/science/article/pii/s0031320321003356},
 pages = {108148},
 volume = {120},
 issn = {0031-3203},
 journal = {Pattern Recognition},
 doi = {10.1016/j.patcog.2021.108148},
 file = {Bandara, Hewamalage et al. 2021 - Improving the accuracy of global:Attachments/Bandara, Hewamalage et al. 2021 - Improving the accuracy of global.pdf:application/pdf}
}


@article{Baptista,
 author = {Baptista, Claudio and Reis, Antonio and Nussbaumer, Alain},
 year = {2017},
 title = {Probabilistic S-N curves for constant and variable amplitude},
 url = {https://www.sciencedirect.com/science/article/pii/s0142112317300300},
 pages = {312--327},
 volume = {101},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2017.01.022}
}


@inproceedings{BasVIVRATION,
 author = {Basangar, Santosh and Tripathi, B. N.},
 title = {Literature Review on Fault Detection of Equipment using Machine Learning Techniques},
 publisher = {IEEE},
 booktitle = {2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM)},
 year = {2020},
 doi = {10.1109/iccakm46823.2020.9051543}
}


@book{BattaMahesh,
 abstract = {PDF | Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without... | Find, read and cite all the research you need on ResearchGate},
 author = {{Batta Mahesh}},
 year = {2019},
 title = {Machine Learning Algorithms -A Review},
 url = {https://www.researchgate.net/profile/batta-mahesh/publication/344717762_machine_learning_algorithms_-a_review},
 doi = {10.21275/ART20203995},
 file = {Batta Mahesh 2019 - Machine Learning Algorithms -A Review (2):Attachments/Batta Mahesh 2019 - Machine Learning Algorithms -A Review (2).pdf:application/pdf}
}


@article{Bellows,
 abstract = {Abstract. The current Air Force High Cycle Fatigue (HCF) Materials Damage Tolerance Program investigating the fatigue behavior of Ti-6Al-4V requires the determination of initiation-based endurance limits both with and without associated damage modes. Step testing was evaluated as a means of generating endurance limits with a single specimen for the purpose of evaluating associated damage mode states. Notched specimens were evaluated in order to determine the effect of notches on the fatigue behavior so that geometrical effects associated with damage modes could be separated from non-geometrical (e.g., plasticity, residual stresses, cracking) effects. As part of this program, smooth bar S-N curves were generated at four stress ratios ($-$1, 0.1, 0.5, and 0.8) and compared to endurance limits determined by the step test method using a single specimen. Notch fatigue was conducted at two stress ratios and compared to smooth bar fatigue, and the effect of notch geometry and sampling volume under the notches was examined at a stress ratio of 0.1. The step test method agreed with the conventional S-N curve determined endurance limit in most cases. The different notch geometries and sampling volumes did not appear to effect notch fatigue behavior. This paper presents some of the preliminary results of this ongoing effort.},
 author = {Bellows, Richard S. and Bain, Ken R. and Sheldon, Jerry W.},
 year = {2022},
 title = {Effect of Step Testing and Notches on the Endurance Limit of Ti-6Al-4V},
 pages = {27--32},
 journal = {ASME 1998 International Mechanical Engineering Congress and Exposition},
 doi = {10.1115/IMECE1998-1138}
}


@article{Benedetti,
 author = {Benedetti, M.},
 year = {2002},
 title = {Influence of shot peening on bending tooth fatigue limit of case hardened gears},
 url = {https://www.sciencedirect.com/science/article/pii/s0142112302000348},
 pages = {1127--1136},
 volume = {24},
 number = {11},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/S0142-1123(02)00034-8}
}


@book{Bergstra,
 author = {Bergstra, James and Yamins, Dan and Cox, David},
 year = {2013},
 title = {Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms},
 url = {https://pdfs.semanticscholar.org/d4f4/9717c9adb46137f49606ebbdf17e3598b5a5.pdf},
 file = {Bergstra, Yamins et al. 2013 - Hyperopt A Python Library:Attachments/Bergstra, Yamins et al. 2013 - Hyperopt A Python Library.pdf:application/pdf}
}


@article{Bertolini,
 author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
 year = {2021},
 title = {Machine Learning for industrial applications: A comprehensive literature review},
 url = {https://www.sciencedirect.com/science/article/pii/s095741742100261x},
 pages = {114820},
 volume = {175},
 issn = {0957-4174},
 journal = {Expert Systems with Applications},
 doi = {10.1016/j.eswa.2021.114820}
}


@article{Bertolini2,
 author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
 year = {2021},
 title = {Machine Learning for industrial applications: A comprehensive literature review},
 url = {https://www.sciencedirect.com/science/article/pii/s095741742100261x},
 pages = {114820},
 volume = {175},
 issn = {0957-4174},
 journal = {Expert Systems with Applications},
 doi = {10.1016/j.eswa.2021.114820}
}


@book{Bishop,
 author = {Bishop, Christopher M.},
 year = {2006},
 title = {Pattern recognition and machine learning},
 address = {New York, NY},
 publisher = {Springer},
 isbn = {978-0387-31073-2},
 series = {Computer science},
 file = {Bishop 2006 - Pattern recognition and machine learning:Attachments/Bishop 2006 - Pattern recognition and machine learning.pdf:application/pdf}
}


@proceedings{Bodden.2017,
 year = {2017},
 title = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
 address = {New York, NY},
 publisher = {ACM},
 isbn = {9781450351058},
 series = {ACM Digital Library},
 editor = {Bodden, Eric},
 institution = {{Association for Computing Machinery-Digital Library} and {Association for Computing Machinery}},
 doi = {10.1145/3106237}
}


@book{Bugliarello,
 author = {{Nicholas Bugliarello, Biji George, Don Giessel, Dan McCurdy, Ron Perkins, Steve Richardson, and Craig Zimmerman}},
 year = {2013},
 title = {Heat Treat Process for Gears},
 url = {http://thermalprocessing.com/media/uploads/assets/pdf/articles/2013_spring/2013_bodycote.pdf},
 file = {Nicholas Bugliarello, Biji George, Don Giessel, Dan McCurdy, Ron Perkins, Steve Richardson, and Crai:Attachments/Nicholas Bugliarello, Biji George, Don Giessel, Dan McCurdy, Ron Perkins, Steve Richardson, and Crai.pdf:application/pdf}
}


@article{Burhan,
 abstract = {S-N behavior has been a backbone of material fatigue life studies since the 19th century. Numerous S-N curve models have been produced but they have been arbitrarily chosen in numerous research works dominantly for composite materials. In this paper, they were critically reviewed and evaluated for capability using the following criteria: data fitting capability, efficiency of curve fitting, applicability to data sets at various stress ratios ($-$0.43, $-$1, $-$3, 0.1, and 10), representability of fatigue damage at failure, and satisfaction of the initial boundary condition. The S-N curve models were found to be in two categories---one for fatigue data characterization independent of stress ratio, and the other for those designed for predicting the effect of stress ratio. The models proposed by Weibull, Sendeckyj, and Kim and Zhang for fatigue data characterization appeared to have the best capabilities for experimental data obtained from Weibull for R = $-$1, from Sendeckyj for R = 0.1, and from Kawai and Itoh (for R = $-$0.43, $-$3, and 10). The Kim and Zhang model was found to have an advantage over the Weibull and the Sendeckyj models for representing the fatigue damage at failure. The Kohout and Vechet model was also found to have a good fitting capability but with an inherent limitation for shaping the S-N curve at some stress ratios (e.g., R = $-$0.43). The S-N curve models developed for predicting the effect of stress ratio were found to be relatively inferior in data fitting capability to those developed directly for fatigue data characterization.},
 author = {Burhan, Ibrahim and Kim, Ho},
 year = {2018},
 title = {S-N Curve Models for Composite Materials Characterisation: An Evaluative Review},
 url = {https://www.mdpi.com/311166},
 pages = {38},
 volume = {2},
 number = {3},
 issn = {2504-477X},
 journal = {Journal of Composites Science},
 doi = {10.3390/jcs2030038},
 file = {Burhan, Kim 2018 - S-N Curve Models for Composite:Attachments/Burhan, Kim 2018 - S-N Curve Models for Composite.pdf:application/pdf}
}


@article{Cai,
 abstract = {Abstract. Physics-informed neural networks (PINNs) have gained popularity across different engineering fields due to their effectiveness in solving realistic problems with noisy data and often partially missing physics. In PINNs, automatic differentiation is leveraged to evaluate differential operators without discretization errors, and a multitask learning problem is defined in order to simultaneously fit observed data while respecting the underlying governing laws of physics. Here, we present applications of PINNs to various prototype heat transfer problems, targeting in particular realistic conditions not readily tackled with traditional computational methods. To this end, we first consider forced and mixed convection with unknown thermal boundary conditions on the heated surfaces and aim to obtain the temperature and velocity fields everywhere in the domain, including the boundaries, given some sparse temperature measurements. We also consider the prototype Stefan problem for two-phase flow, aiming to infer the moving interface, the velocity and temperature fields everywhere as well as the different conductivities of a solid and a liquid phase, given a few temperature measurements inside the domain. Finally, we present some realistic industrial applications related to power electronics to highlight the practicality of PINNs as well as the effective use of neural networks in solving general heat transfer problems of industrial complexity. Taken together, the results presented herein demonstrate that PINNs not only can solve ill-posed problems, which are beyond the reach of traditional computational methods, but they can also bridge the gap between computational and experimental heat transfer.},
 author = {Cai, Shengze and Wang, Zhicheng and Wang, Sifan and Perdikaris, Paris and Karniadakis, George Em},
 year = {2021},
 title = {Physics-Informed Neural Networks for Heat Transfer Problems},
 volume = {143},
 number = {6},
 issn = {0022-1481},
 journal = {Journal of Heat Transfer},
 doi = {10.1115/1.4050542},
 file = {Cai, Wang et al. 2021 - Physics-Informed Neural Networks for Heat:Attachments/Cai, Wang et al. 2021 - Physics-Informed Neural Networks for Heat.pdf:application/pdf}
}


@article{Carleo,
 author = {Carleo, Giuseppe and Cirac, Ignacio and Cranmer, Kyle and Daudet, Laurent and Schuld, Maria and Tishby, Naftali and Vogt-Maranto, Leslie and Zdeborov{\'a}, Lenka},
 year = {2019},
 title = {Machine learning and the physical sciences},
 volume = {91},
 number = {4},
 issn = {0034-6861},
 journal = {Reviews of Modern Physics},
 doi = {10.1103/RevModPhys.91.045002},
 file = {Carleo, Cirac et al 2019 - Machine learning and the physical:Attachments/Carleo, Cirac et al 2019 - Machine learning and the physical.pdf:application/pdf}
}


@article{Carvalho,
 author = {Carvalho, Thyago P. and Soares, Fabr{\'i}zzio A. A. M. N. and Vita, Roberto and {Da Francisco}, Roberto P. and Basto, Jo{\~a}o P. and Alcal{\'a}, Symone G. S.},
 year = {2019},
 title = {A systematic literature review of machine learning methods applied to predictive maintenance},
 url = {https://www.sciencedirect.com/science/article/pii/s0360835219304838},
 pages = {106024},
 volume = {137},
 issn = {0360-8352},
 journal = {Computers {\&} Industrial Engineering},
 doi = {10.1016/j.cie.2019.106024}
}


@book{Chauvin,
 abstract = {Composed of three sections, this book presents the most popular training algorithm for neural networks: backpropagation. The first section presents the theory and principles behind backpropagation as seen from different perspectives such as statistics, machine learning, and dynamical systems. The second presents a number of network architectures that may be designed to match the general concepts of Parallel Distributed Processing with backpropagation learning. Finally, the third section shows how these principles can be applied to a number of different fields related to the cognitive sciences, including control, speech recognition, robotics, image processing, and cognitive psychology. The volume is designed to provide both a solid theoretical foundation and a set of examples that show the versatility of the concepts. Useful to experts in the field, it should also be most helpful to students seeking to understand the basic principles of connectionist learning and to engineers wanting to add neural networks in general -- and backpropagation in particular -- to their set of problem-solving methods.},
 author = {Chauvin, Yves and Rumelhart, David E.},
 year = {1995},
 title = {Backpropagation: Theory, architectures, and applications},
 address = {Hillsdale, N.J.},
 publisher = {{Lawrence Erlbaum Associates, Inc}},
 isbn = {9781134775811},
 series = {Developments in connectionist theory Back propagation},
 file = {Chauvin, Rumelhart 1995 - Backpropagation:Attachments/Chauvin, Rumelhart 1995 - Backpropagation.pdf:application/pdf}
}


@article{Chen,
 author = {Chen, Jie and Imanian, Anahita and Wei, Haoyang and Iyyer, Nagaraja and Liu, Yongming},
 year = {2020},
 title = {Piecewise stochastic rainflow counting for probabilistic linear and nonlinear damage accumulation considering loading and material uncertainties},
 url = {https://www.sciencedirect.com/science/article/pii/s014211232030373x},
 pages = {105842},
 volume = {140},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2020.105842}
}


@book{Claesen,
 abstract = {We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.},
 author = {Claesen, Marc and de Moor, Bart},
 year = {2015},
 title = {Hyperparameter Search in Machine Learning},
 url = {https://arxiv.org/pdf/1502.02127},
 file = {Claesen, Moor 2015 - Hyperparameter Search in Machine Learning:Attachments/Claesen, Moor 2015 - Hyperparameter Search in Machine Learning.pdf:application/pdf}
}


@article{Cuomo,
 abstract = {Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.},
 author = {Cuomo, Salvatore and {Di Cola}, Vincenzo Schiano and Giampaolo, Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli, Francesco},
 year = {2022},
 title = {Scientific Machine Learning Through Physics--Informed Neural Networks: Where we are and What's Next},
 url = {https://link.springer.com/article/10.1007/s10915-022-01939-z},
 pages = {1--62},
 volume = {92},
 number = {3},
 issn = {1573-7691},
 journal = {Journal of Scientific Computing},
 doi = {10.1007/s10915-022-01939-z},
 file = {Cuomo, Di Cola et al. 2022 - Scientific Machine Learning Through Physics-Informed:Attachments/Cuomo, Di Cola et al. 2022 - Scientific Machine Learning Through Physics-Informed.pdf:application/pdf}
}


@article{Das,
 abstract = {Topologically stable magnetic skyrmion has a much lower depinning current density that may be useful for memory as well as neuromorphic computing. However, skyrmion-based devices suffer from the Magnus force originating from the skyrmion Hall effect, which may result in unwanted skyrmion annihilation if the magnitude of the driving current gets too large. A design of an artificial neuron and a synapse using a synthetic antiferromagnetically coupled bilayer device, which nullifies the Magnus force, is demonstrated in this work. The leak term in the artificial leaky integrate-and-fire neuron is achieved by engineering the uniaxial anisotropy profile of the neuronal device. The synaptic device has a similar structure as the neuronal device but has a constant uniaxial anisotropy. The synaptic device also has a linear and symmetric weight update, which is a highly desirable trait of an artificial synapse. Neuronal and synaptic devices based on magnetic domain-wall (DW) motion are also studied and compared to skyrmionic devices. Our simulation results show the energy required to perform such operation in DW or skyrmion-based devices is on the order of a few fJ.},
 author = {Das, Debasis and Cen, Yunuo and Wang, Jianze and Fong, Xuanyao},
 year = {2022},
 title = {Design of Spintronics-based Neuronal and Synaptic Devices for Spiking  Neural Network Circuits},
 url = {https://arxiv.org/pdf/2211.06630},
 file = {Das, Cen et al. 12 11 2022 - Design of Spintronics-based Neuronal:Attachments/Das, Cen et al. 12 11 2022 - Design of Spintronics-based Neuronal.pdf:application/pdf}
}


@article{Deiana,
 abstract = {In this community review report, we discuss applications and techniques for fast machine learning (ML) in science-the concept of integrating powerful ML methods into the real-time experimental data processing loop to accelerate scientific discovery. The material for the report builds on two workshops held by the Fast ML for Science community and covers three main areas: applications for fast ML across a number of scientific domains; techniques for training and implementing performant and resource-efficient ML algorithms; and computing architectures, platforms, and technologies for deploying these algorithms. We also present overlapping challenges across the multiple scientific domains where common solutions can be found. This community report is intended to give plenty of examples and inspiration for scientific discovery through integrated and accelerated ML solutions. This is followed by a high-level overview and organization of technical advances, including an abundance of pointers to source material, which can enable these breakthroughs.},
 author = {Deiana, Allison McCarn and Tran, Nhan and Agar, Joshua and Blott, Michaela and {Di Guglielmo}, Giuseppe and Duarte, Javier and Harris, Philip and Hauck, Scott and Liu, Mia and Neubauer, Mark S. and Ngadiuba, Jennifer and Ogrenci-Memik, Seda and Pierini, Maurizio and Aarrestad, Thea and B{\"a}hr, Steffen and Becker, J{\"u}rgen and Berthold, Anne-Sophie and Bonventre, Richard J. and {M{\"u}ller Bravo}, Tom{\'a}s E. and Diefenthaler, Markus and Dong, Zhen and Fritzsche, Nick and Gholami, Amir and Govorkova, Ekaterina and Guo, Dongning and Hazelwood, Kyle J. and Herwig, Christian and Khan, Babar and Kim, Sehoon and Klijnsma, Thomas and Liu, Yaling and Lo, Kin Ho and Nguyen, Tri and Pezzullo, Gianantonio and Rasoulinezhad, Seyedramin and Rivera, Ryan A. and Scholberg, Kate and Selig, Justin and Sen, Sougata and Strukov, Dmitri and Tang, William and Thais, Savannah and Unger, Kai Lukas and Vilalta, Ricardo and von Krosigk, Belina and Wang, Shen and Warburton, Thomas K.},
 year = {2022},
 title = {Applications and Techniques for Fast Machine Learning in Science},
 url = {https://www.frontiersin.org/articles/10.3389/fdata.2022.787421/full},
 pages = {787421},
 volume = {5},
 issn = {2624-909X},
 journal = {Frontiers in Big Data},
 doi = {10.3389/fdata.2022.787421},
 file = {Deiana, Tran et al. 2022 - Applications and Techniques for Fast:Attachments/Deiana, Tran et al. 2022 - Applications and Techniques for Fast.pdf:application/pdf}
}


@article{Deutsch,
 author = {Deutsch, Jason and He, David},
 year = {2018},
 title = {Using Deep Learning-Based Approach to Predict Remaining Useful Life of Rotating Components},
 pages = {11--20},
 volume = {48},
 number = {1},
 issn = {2168-2216},
 journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
 doi = {10.1109/tsmc.2017.2697842},
 file = {Deutsch, He 2018 - Using Deep Learning-Based Approach:Attachments/Deutsch, He 2018 - Using Deep Learning-Based Approach.pdf:application/pdf}
}


@misc{DIN50100,
 author = {{DIN - Deutsches Institut f{\"u}r Normung}},
 year = {2015},
 title = {DIN 50100 Schwingfestigkeitsversuch-Aktueller Stand der {\"U}berarbeitung},
 url = {https://opus4.kobv.de/opus4-bam/frontdoor/index/index/docid/35176}
}


@inproceedings{Ding,
 author = {Ding, Bin and Qian, Huimin and Zhou, Jun},
 title = {Activation functions and their characteristics in deep neural networks},
 publisher = {IEEE},
 booktitle = {2018 Chinese Control And Decision Conference (CCDC)},
 year = {2018},
 doi = {10.1109/ccdc.2018.8407425}
}


@article{Divya,
 abstract = {Review of fault detection techniques for predictive maintenance - Author: D. Divya, Bhasi Marath, M.B. Santosh Kumar},
 author = {Divya, D. and Marath, Bhasi and {Santosh Kumar}, M. B.},
 year = {2023},
 title = {Review of fault detection techniques for predictive maintenance},
 url = {https://www.emerald.com/insight/content/doi/10.1108/jqme-10-2020-0107/full/pdf},
 pages = {420--441},
 volume = {29},
 number = {2},
 issn = {1355-2511},
 journal = {Journal of Quality in Maintenance Engineering},
 doi = {10.1108/JQME-10-2020-0107}
}


@article{Dong,
 abstract = {As reported in the last OMAE conference (Dong, 2003), a robust structural stress method has been developed and validated for fatigue evaluation of ship structures through a major joint industry project. The structural stress method not only provides a consistent method for characterizing stress concentration effects on fatigue in different joint types and loading modes, but also offers a rapid estimation procedure for stress intensity factors for arbitrary joint geometries and loading modes in fracture mechanics context. As a result, a master S-N curve approach has been recently developed by using the mesh-insensitive structural stress parameter and its direct linkage to fracture mechanics principles. The master S-N curve is described by an equivalent structural stress range parameter which provides a single parameter description of stress concentration effects, thickness effects, and loading mode effects on fatigue in welded joints. A massive amount of S-N data since 1947, encompassing drastically different joint types, plate thickness, and loading modes have been used to validate the effectiveness of the master S-N curve approach. With the master S-N curve method, plate joints in ship structures, tubular joints in offshore structures, as well as pipe joints for riser applications can be collapsed into a singe curve, referred to as the master S-N curve. This paper provides the detailed theoretical development, application examples, and validation results. The applications for the master S-N curve approach will be illustrated by using various offshore/marine examples.},
 author = {Dong, P. and Hong, J. K.},
 year = {2008},
 title = {The Master S-N Curve Approach to Fatigue Evaluation of Offshore and Marine Structures},
 pages = {847--855},
 journal = {ASME 2004 23rd International Conference on Offshore Mechanics and Arctic Engineering},
 doi = {10.1115/OMAE2004-51324}
}


@article{Facchinetti,
 author = {Facchinetti, Matteo Luca},
 year = {2018},
 title = {Fatigue damage of materials and structures assessed by W{\"o}hler and Gassner frameworks: recent insights about load spectra for the automotive},
 url = {https://www.sciencedirect.com/science/article/pii/s1877705818302352},
 pages = {117--125},
 volume = {213},
 issn = {1877-7058},
 journal = {Procedia Engineering},
 doi = {10.1016/j.proeng.2018.02.013}
}


@inproceedings{Fu,
 author = {Fu, Wei and Menzies, Tim},
 title = {Easy over hard: a case study on deep learning},
 pages = {49--60},
 publisher = {ACM},
 isbn = {9781450351058},
 series = {ACM Digital Library},
 editor = {Bodden, Eric},
 booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
 year = {2017},
 address = {New York, NY},
 doi = {10.1145/3106237.3106256},
 file = {Fu, Menzies 08212017 - Easy over hard:Attachments/Fu, Menzies 08212017 - Easy over hard.pdf:application/pdf}
}


@article{Gao,
 abstract = {Many structures are subjected to variable amplitude loading in engineering practice. The foundation of fatigue life prediction under variable amplitude loading is how to deal with the fatigue damage accumulation. A nonlinear fatigue damage accumulation model to consider the effects of load sequences was proposed in earlier literature, but the model cannot consider the load interaction effects, and sometimes it makes a major error. A modified nonlinear damage accumulation model is proposed in this paper to account for the load interaction effects. Experimental data of two metallic materials are used to validate the proposed model. The agreement between the model prediction and experimental data is observed, and the predictions by proposed model are more possibly in accordance with experimental data than that by primary model and Miner's rule. Comparison between the predicted cumulative damage by the proposed model and an existing model shows that the proposed model predictions can meet the accuracy requirement of the engineering project and it can be used to predict the fatigue life of welded aluminum alloy joint of Electric Multiple Units (EMU); meanwhile, the accuracy of approximation can be obtained from the proposed model though more simple computing process and less material parameters calling for extensive testing than the existing model.},
 author = {Gao, Huiying and Huang, Hong-Zhong and Zhu, Shun-Peng and Li, Yan-Feng and Yuan, Rong},
 year = {2014},
 title = {A modified nonlinear damage accumulation model for fatigue life prediction considering load interaction effects},
 url = {https://www.hindawi.com/journals/tswj/2014/164378/},
 pages = {164378},
 volume = {2014},
 journal = {TheScientificWorldJournal},
 doi = {10.1155/2014/164378},
 file = {Gao, Huang et al. 2014 - A modified nonlinear damage accumulation:Attachments/Gao, Huang et al. 2014 - A modified nonlinear damage accumulation.pdf:application/pdf}
}


@article{Gao1,
 abstract = {Many structures are subjected to variable amplitude loading in engineering practice. The foundation of fatigue life prediction under variable amplitude loading is how to deal with the fatigue damage accumulation. A nonlinear fatigue damage accumulation model to consider the effects of load sequences was proposed in earlier literature, but the model cannot consider the load interaction effects, and sometimes it makes a major error. A modified nonlinear damage accumulation model is proposed in this paper to account for the load interaction effects. Experimental data of two metallic materials are used to validate the proposed model. The agreement between the model prediction and experimental data is observed, and the predictions by proposed model are more possibly in accordance with experimental data than that by primary model and Miner's rule. Comparison between the predicted cumulative damage by the proposed model and an existing model shows that the proposed model predictions can meet the accuracy requirement of the engineering project and it can be used to predict the fatigue life of welded aluminum alloy joint of Electric Multiple Units (EMU); meanwhile, the accuracy of approximation can be obtained from the proposed model though more simple computing process and less material parameters calling for extensive testing than the existing model.},
 author = {Gao, Huiying and Huang, Hong-Zhong and Zhu, Shun-Peng and Li, Yan-Feng and Yuan, Rong},
 year = {2014},
 title = {A modified nonlinear damage accumulation model for fatigue life prediction considering load interaction effects},
 url = {https://www.hindawi.com/journals/tswj/2014/164378/},
 pages = {164378},
 volume = {2014},
 journal = {TheScientificWorldJournal},
 doi = {10.1155/2014/164378},
 file = {Gao, Huang et al. 2014 - A modified nonlinear damage accumulation (2):Attachments/Gao, Huang et al. 2014 - A modified nonlinear damage accumulation (2).pdf:application/pdf}
}


@book{Goodfellow,
 author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
 year = {2016},
 title = {Deep learning},
 price = {Hardcover : GBP 66.95},
 address = {Cambridge, Massachusetts and London, England},
 publisher = {{The MIT Press}},
 isbn = {9780262035613},
 series = {Adaptive computation and machine learning},
 institution = {{MIT Press}},
 file = {Goodfellow, Bengio et al 2016 - Deep learning:Attachments/Goodfellow, Bengio et al 2016 - Deep learning.pdf:application/pdf}
}


@misc{google,
 author = {Google},
 year = {2023},
 title = {Machine Learning Glossary: Acces Date: 20/05/2023},
 url = {https://developers.google.com/machine-learning/glossary?hl=de},
 file = {Machine Learning Glossary:Attachments/Machine Learning Glossary.pdf:application/pdf}
}


@article{Goyal,
 abstract = {Activation functionsActivation functions~lie at the core of deep neural networksLearning deep neural networks allowing them to learn arbitrarily complex mappings. Without any activation, a neural network learn will only be able to learn a linear relation between...},
 author = {Goyal, Mohit and Goyal, Rajan and {Venkatappa Reddy}, P. and Lall, Brejesh},
 year = {2020},
 title = {Activation Functions},
 url = {https://link.springer.com/chapter/10.1007/978-3-030-31760-7_1},
 pages = {1--30},
 doi = {10.1007/978-3-030-31760-7{\textunderscore }1},
 file = {Goyal, Goyal et al. 2020 - Activation Functions (2):Attachments/Goyal, Goyal et al. 2020 - Activation Functions (2).pdf:application/pdf}
}


@article{Grossberg,
 author = {Grossberg, Stephen},
 year = {2013},
 title = {Recurrent neural networks},
 url = {http://scholarpedia.org/article/recurrent_neural_network},
 pages = {1888},
 volume = {8},
 number = {2},
 issn = {1941-6016},
 journal = {Scholarpedia},
 doi = {10.4249/scholarpedia.1888},
 file = {Grossberg 2013 - Recurrent neural networks:Attachments/Grossberg 2013 - Recurrent neural networks.pdf:application/pdf;Grossberg 2013 - Recurrent neural networks (2):Attachments/Grossberg 2013 - Recurrent neural networks (2).pdf:application/pdf}
}


@article{Guo,
 abstract = {The various studies of partial differential equations (PDEs) are hot topics of mathematical research. Among them, solving PDEs is a very important and difficult task. Since many partial differential equations do not have analytical solutions, numerical methods are widely used to solve PDEs. Although numerical methods have been widely used with good performance, researchers are still searching for new methods for solving partial differential equations. In recent years, deep learning has achieved great success in many fields, such as image classification and natural language processing. Studies have shown that deep neural networks have powerful function-fitting capabilities and have great potential in the study of partial differential equations. In this paper, we introduce an improved Physics Informed Neural Network (PINN) for solving partial differential equations. PINN takes the physical information that is contained in partial differential equations as a regularization term, which improves the performance of neural networks. In this study, we use the method to study the wave equation, the KdV--Burgers equation, and the KdV equation. The experimental results show that PINN is effective in solving partial differential equations and deserves further research.},
 author = {Guo, Yanan and Cao, Xiaoqun and Liu, Bainian and Gao, Mei},
 year = {2020},
 title = {Solving Partial Differential Equations Using Deep Learning and Physical Constraints},
 url = {https://www.mdpi.com/808808},
 pages = {5917},
 volume = {10},
 number = {17},
 journal = {Applied Sciences},
 doi = {10.3390/app10175917},
 file = {Guo, Cao et al. 2020 - Solving Partial Differential Equations Using:Attachments/Guo, Cao et al. 2020 - Solving Partial Differential Equations Using.pdf:application/pdf}
}


@book{Haibach,
 abstract = {Das Bemessungskonzept {\textquotedbl}Betriebsfestigkeit{\textquotedbl} verfolgt das Ziel, Maschinen, Fahrzeuge oder andere Konstruktionen gegen zeitlich ver{\"a}nderliche Betriebslasten unter Ber{\"u}cksichtigung ihrer Umgebungsbedingungen f{\"u}r eine bestimmte Nutzungsdauer zuverl{\"a}ssig bemessen zu k{\"o}nnen. Ingenieure, Wissenschaftler und Studenten finden in diesem Buch die experimentellen Grundlagen sowie erprobte und neuere Rechenverfahren der Betriebsfestigkeit f{\"u}r eine ingenieurm{\"a}{\ss}ige Anwendung. Verfahren nach dem Nennspannungs-Konzept, dem Kerbgrund-Konzept und dem Bruchmechanik-Konzept werden vor ihrem theoretischen Hintergrund nach heutigem Erkenntnisstand behandelt. Der Autor zeigt auf, in welchen Grenzen die betreffenden Verfahren als verl{\"a}{\ss}lich angesehen werden d{\"u}rfen. Zur Dauerfestigkeit bei hohen Schwingungszahlen sowie zu Eigenschaften von Faserverbundwerkstoffen wurden neue Erkenntnisse eingef{\"u}gt. F{\"u}r den Betriebsfestigkeits-Nachweis in der Konstruktionspraxis gibt dieses Buch konkrete Hinweise.},
 author = {Haibach, Erwin},
 year = {2006},
 title = {Betriebsfestigkeit: Verfahren und Daten zur Bauteilberechnung},
 address = {Berlin, Heidelberg},
 edition = {3. Auflage},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {9783540293644},
 series = {VDI-Buch},
 doi = {Erwin}
}


@book{Hamilton,
 abstract = {Frontmatter -- Contents -- Preface -- 1 Difference Equations -- 1.1. First-Order Difference Equations -- 1.2. pth-Order Difference Equations -- APPENDIX I.A. Proofs of Chapter 1 Propositions -- Chapter 1 References -- 2 Lag Operators -- 2.1. Introduction -- 2.2. First-Order Difference Equations -- 2.3. Second-Order Difference Equations -- 2.4. pth-Order Difference Equations -- 2.5. Initial Conditions and Unbounded Sequences -- Chapter 2 References -- 3 Stationary ARMA Processes -- 3.1. Expectations, Stationarity, and Ergodicity -- 3.2. White Noise -- 3.3. Moving Average Processes -- 3.4. Autoregressive Processes -- 3.5. Mixed Autoregressive Moving Average Processes -- 3.6. The Autocovariance-Generating Function -- 3.7. Invertibility -- APPENDIX 3.A. Convergence Results for Infinite-Order Moving Average Processes -- Chapter 3 Exercises -- Chapter 3 References -- 4 Forecasting -- 4.1. Principles of Forecasting -- 4.2. Forecasts Based on an Infinite Number of Observations -- 4.3. Forecasts Based on a Finite Number of Observations -- 4.4. The Triangular Factorization of a Positive Definite Symmetric Matrix -- 4.5. Updating a Linear Projection -- 4.6. Optimal Forecasts for Gaussian Processes -- 4.7. Sums of ARM A Processes -- 4.8. Wold's Decomposition and the Box-Jenkins Modeling Philosophy -- APPENDIX 4.A. Parallel Between OLS Regression and Linear Projection -- APPENDIX 4.B. Triangular Factorization of the Covariance Matrix for an MA(1) Process -- Chapter 4 Exercises -- Chapter 4 References -- 5 Maximum Likelihood Estimation -- 5.1. Introduction -- 5.2. The Likelihood Function for a Gaussian AR(7J Process -- 5.3. The Likelihood Function for a Gaussian AR(p) Process -- 5.4. The Likelihood Function for a Gaussian MA(1) Process -- 5.5. The Likelihood Function for a Gaussian MA(q) Process -- 5.6. The Likelihood Function for a Gaussian ARMA(p, q) Process -- 5.7. Numerical Optimization -- 5.8. Statistical Inference with Maximum Likelihood Estimation -- 5.9. Inequality Constraints -- APPENDIX 5. A. Proofs of Chapter 5 Propositions -- Chapter 5 Exercises -- Chapter 5 References -- 6 Spectral Analysis -- 6.1. The Population Spectrum -- 6.2. The Sample Periodogram -- 6.3. Estimating the Population Spectrum -- 6.4. Uses of Spectral Analysis -- APPENDIX 6. A. Proofs of Chapter 6 Propositions -- Chapter 6 Exercises -- Chapter 6 References -- 7 Asymptotic Distribution Theory -- 7.1. Review of Asymptotic Distribution Theory -- 7.2. Limit Theorems for Serially Dependent Observations -- APPENDIX 7.A. Proofs of Chapter 7 Propositions -- Chapter 7 Exercises -- Chapter 7 Exercises -- 8 Linear Regression Models -- 8.1. Review of Ordinary Least Squares with Deterministic Regressors and i.i.d. Gaussian Disturbances -- 8.2. Ordinary Least Squares Under More General Conditions -- 8.3. Generalized Least Squares -- APPENDIX 8. A. Proofs of Chapter 8 Propositions -- Chapter 8 Exercises -- Chapter 8 References -- 9 Linear Systems of Simultaneous Equations -- 9.1. Simultaneous Equations Bias -- 9.2. Instrumental Variables and Two-Stage Least Squares -- 9.3. Identification -- 9.4. Full-Information Maximum Likelihood Estimation -- 9.5 Estimation Based on the Reduced Form -- 9.6. Overview of Simultaneous Equations Bias -- APPENDIX 9.A. Proofs of Chapter 9 Proposition -- Chapter 9 Exercise -- Chapter 9 References -- 10 Covariance-Stationary Vector Processes -- 10.1. Introduction to Vector Autoregressions -- 10.2. Autocovariances and Convergence Results for Vector Processes -- 10.3. The Autocovariance-Generating Function for Vector Processes -- 10.4. The Spectrum for Vector Processes -- 10.5. The Sample Mean of a Vector Process -- APPENDIX 10.A. Proofs of Chapter 10 Propositions -- Chapter 10 Exercises -- Chapter 10 References -- 11 Vector Autoregressions -- 11.1. Maximum Likelihood Estimation and Hypothesis Testing for an Unrestricted Vector Autoregression -- 11.2. Bivariate Granger Causality Tests -- 11.3. Maximum Likelihood Estimation of Restricted Vector Autoregressions -- 11.4. The Impulse-Response Function -- 11.5. Variance Decomposition -- 11.6. Vector Autoregressions and Structural Econometric Models -- 11.7. Standard Errors for Impulse-Response Functions -- APPENDIX 11. A. Proofs of Chapter 11 Propositions -- APPENDIX 11.B. Calculation of Analytic Derivatives -- Chapter 11 Exercises -- Chapter 11 References -- 12 Bayesian Analysis -- 12.1. Introduction to Bayesian Analysis -- 12.2. Bayesian Analysis of Vector Autoregressions -- 12.3. Numerical Bayesian Methods -- APPENDIX 12.A. Proofs of Chapter 12 Propositions -- Chapter 12 Exercise -- Chapter 12 References -- 13 The Kalman Filter -- 13.1. The State-Space Representation of a Dynamic System -- 13.2. Derivation of the Kalman Filter -- 13.3. Forecasts Based on the State-Space Representation -- 13.4. Maximum Likelihood Estimation -- 13.5. The Steady-State Kalman Filter -- 13.6. Smoothing -- 13.7. Statistical Inference with the Kalman Filter -- 13.8. Time-Varying Parameters -- APPENDIX 13. A. Proofs of Chapter 13 Propositions -- Chapter 13 Exercises -- Chapter 13 References -- 14 Generalized Method of Moments -- 14.1. Estimation by the Generalized Method of Moments -- 14.2. Examples -- 14.3. Extensions -- 14.4. GMM and Maximum Likelihood Estimation -- APPENDIX 14. A. Proof of Chapter 14 Proposition -- Chapter 14 Exercise -- Chapter 14 References -- 15 Models of Nonstationary Time Series -- 15.1. Introduction -- 15.2. Why Linear Time Trends and Unit Roots? -- 15.3. Comparison of Trend-Stationary and Unit Root Processes -- 15.4. The Meaning of Tests for Unit Roots -- 15.5. Other Approaches to Trended Time Series -- APPENDIX 15. A. Derivation of Selected Equations for Chapter 15 -- Chapter 15 References -- 16 Processes with Deterministic Time Trends -- 16.1. Asymptotic Distribution of OLS Estimates of the Simple Time Trend Model -- 16.2. Hypothesis Testing for the Simple Time Trend Model -- 16.3. Asymptotic Inference for an Autoregressive Process Around a Deterministic Time Trend -- APPENDIX 16. A. Derivation of Selected Equations for Chapter 16 -- Chapter 16 Exercises -- Chapter 16 References -- 17 Univariate Processes with Unit Roots -- 17.1. Introduction -- 17.2. Brownian Motion -- 17.3. The Functional Central Limit Theorem -- 17.4. Asymptotic Properties of a First-Order Autoregression when the True Coefficient Is Unity -- 17.5. Asymptotic Results for Unit Root Processes with General Serial Correlation -- 17.6. Phillips-Perron Tests for Unit Roots -- 17.7. Asymptotic Properties of a pth-Order Autoregression and the Augmented Dickey-Fuller Tests for Unit Roots -- 17.8. Other Approaches to Testing for Unit Roots -- 17.9. Bayesian Analysis and Unit Roots -- APPENDIX 17.A. Proofs of Chapter 17 Propositions -- Chapter 17 Exercises -- Chapter 17 References -- 18 Unit Roots in Multivariate Time Series -- 18.1. Asymptotic Results for Nonstationary Vector Processes -- 18.2. Vector Autoregressions Containing Unit Roots -- 18.3. Spurious Regressions -- APPENDIX 18.A. Proofs of Chapter 18 Propositions -- Chapter 18 Exercises -- Chapter 18 References -- 19 Cointegration -- 19.1. Introduction -- 19.2. Testing the Null Hypothesis -- 19.3. Testing Hypotheses About the Cointegrating Vector -- APPENDIX 19. A. Proofs of Chapter 19 Propositions -- Chapter 19 Exercises -- Chapter 19 References -- 20 Full-Information Maximum Likelihood Analysis of Cointegrated Systems -- 20.1. Canonical Correlation -- 20.2. Maximum Likelihood Estimation -- 20.3. Hypothesis Testing -- 20.4. Overview of Unit Roots---To Difference or Not to Difference? -- APPENDIX 20.A. Proof of Chapter 20 Proposition -- Chapter 20 Exercises -- Chapter 20 References -- 21 Time Series Models of Heteroskedasticity -- 21.1. Autoregressive Conditional Heteroskedasticity (ARCH) -- 21.2. Extensions -- APPENDIX 21. A. Derivation of Selected Equations for Chapter 21 -- Chapter 21 References -- 22 Modeling Time Series with Changes in Regime -- 22.1. Introduction -- 22.2. Markov Chains -- 22.3. Statistical Analysis of i.i.d. Mixture Distributions -- 22.4.



Time Series Models of Changes in Regime -- APPENDIX 22. A. Derivation of Selected Equations for Chapter 22 -- Chapter 22 Exercise -- Chapter 22 Reference -- A Mathematical Review -- A.1. Trigonometry -- A.2. Complex Numbers -- A.3. Calculus -- A.4. Matrix Algebra -- A.5. Probability and Statistics -- Appendix A References -- B Statistical Tables -- C Answers to Selected Exercises -- D Greek Letters and Mathematical Symbols Used in the Text -- Author Index -- Subject Index



The last decade has brought dramatic changes in the way that researchers analyze economic and financial time series. This book synthesizes these recent advances and makes them accessible to first-year graduate students. James Hamilton provides the first adequate text-book treatments of important innovations such as vector autoregressions, generalized method of moments, the economic and statistical consequences of unit roots, time-varying variances, and nonlinear time series models. In addition, he presents basic tools for analyzing dynamic systems (including linear representations, autocovariance generating functions, spectral analysis, and the Kalman filter) in a way that integrates economic theory with the practical difficulties of analyzing and interpreting real-world data. Time Series Analysis fills an important need for a textbook that integrates economic theory, econometrics, and new results. The book is intended to provide students and researchers with a self-contained survey of time series analysis. It starts from first principles and should be readily accessible to any beginning graduate student, while it is also intended to serve as a reference book for researchers},
 author = {Hamilton, James Douglas},
 year = {2020},
 title = {Time Series Analysis},
 address = {Princeton, NJ},
 publisher = {{Princeton University Press}},
 isbn = {9780691218632},
 doi = {10.1515/9780691218632},
 file = {Hamilton 2020 - Time Series Analysis:Attachments/Hamilton 2020 - Time Series Analysis.pdf:application/pdf}
}


@article{Hanumanna,
 author = {Hanumanna, D. and Narayanan, S. and Krishnamurthy, S.},
 year = {2001},
 title = {Bending fatigue testing of gear teeth under random loading},
 pages = {773--784},
 volume = {215},
 number = {7},
 issn = {0954-4062},
 journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
 doi = {10.1243/0954406011524135},
 file = {Hanumanna, Narayanan et al 2001 - Bending fatigue testing of gear:Attachments/Hanumanna, Narayanan et al 2001 - Bending fatigue testing of gear.pdf:application/pdf}
}


@article{He,
 abstract = {Abstract. As a transmission component, the gear has been obtained widespread attention. The remaining useful life (RUL) prediction of gear is critical to the prognostics health management (PHM) of gear transmission systems. The digital twin (DT) provides support for gear RUL prediction with the advantages of rich health information data and accurate health indicators (HI). This paper reviews digital twin-driven RUL prediction methods for gear performance degradation, from the view of digital twin-driven physical model-based and virtual model-based prediction method. From the view of the physical model-based one, it includes a prediction model based on gear crack, gear fatigue, gear surface scratch, gear tooth breakage, and gear permanent deformation. From the view of the digital twin-driven virtual model-based one, it includes non-deep learning methods and deep learning methods. Non-deep learning methods include the wiener process, gamma process, hidden Markov model (HMM), regression-based model, and proportional hazard model. Deep learning methods include deep neural networks (DNN), deep belief networks (DBN), convolutional neural networks (CNN), and recurrent neural networks (RNN). It mainly summarizes the performance degradation and life test of various models in gear and evaluates the advantages and disadvantages of various methods. In addition, it encourages future works.},
 author = {He, Bin and Liu, Long and Zhang, Dong},
 year = {2021},
 title = {Digital Twin-Driven Remaining Useful Life Prediction for Gear Performance Degradation: A Review},
 volume = {21},
 number = {3},
 issn = {1530-9827},
 journal = {Journal of Computing and Information Science in Engineering},
 doi = {10.1115/1.4049537}
}


@article{Helm,
 abstract = {PURPOSE OF REVIEW

With the unprecedented advancement of data aggregation and deep learning algorithms, artificial intelligence (AI) and machine learning (ML) are poised to transform the practice of medicine. The field of orthopedics, in particular, is uniquely suited to harness the power of big data, and in doing so provide critical insight into elevating the many facets of care provided by orthopedic surgeons. The purpose of this review is to critically evaluate the recent and novel literature regarding ML in the field of orthopedics and to address its potential impact on the future of musculoskeletal care.

RECENT FINDINGS

Recent literature demonstrates that the incorporation of ML into orthopedics has the potential to elevate patient care through alternative patient-specific payment models, rapidly analyze imaging modalities, and remotely monitor patients. Just as the business of medicine was once considered outside the domain of the orthopedic surgeon, we report evidence that demonstrates these emerging applications of AI warrant ownership, leverage, and application by the orthopedic surgeon to better serve their patients and deliver optimal, value-based care.},
 author = {Helm, J. Matthew and Swiergosz, Andrew M. and Haeberle, Heather S. and Karnuta, Jaret M. and Schaffer, Jonathan L. and Krebs, Viktor E. and Spitzer, Andrew I. and Ramkumar, Prem N.},
 year = {2020},
 title = {Machine Learning and Artificial Intelligence: Definitions, Applications, and Future Directions},
 pages = {69--76},
 volume = {13},
 number = {1},
 issn = {1935-973X},
 journal = {Current reviews in musculoskeletal medicine},
 doi = {10.1007/s12178-020-09600-8},
 file = {Helm, Swiergosz et al 2020 - Machine Learning and Artificial Intelligence:Attachments/Helm, Swiergosz et al 2020 - Machine Learning and Artificial Intelligence.pdf:application/pdf}
}


@article{HEULER,
 author = {HEULER, P. and KLATSCHKE, H.},
 year = {2005},
 title = {Generation and use of standardised load spectra and load--time histories},
 url = {https://www.sciencedirect.com/science/article/pii/s014211230500071x},
 pages = {974--990},
 volume = {27},
 number = {8},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2004.09.012},
 file = {HEULER, KLATSCHKE 2005 - Generation and use of standardised:Attachments/HEULER, KLATSCHKE 2005 - Generation and use of standardised.pdf:application/pdf}
}


@book{Huang,
 author = {Huang, Zhongling},
 year = {2020},
 title = {Classification of Large-Scale High-Resolution SAR Images with Deep Transfer Learning},
 publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
 doi = {10.36227/techrxiv.11474400},
 file = {Huang 2020 - Classification of Large-Scale High-Resolution SAR:Attachments/Huang 2020 - Classification of Large-Scale High-Resolution SAR.pdf:application/pdf}
}


@book{Hutter,
 author = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
 year = {2019},
 title = {Automated Machine Learning},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-030-05317-8},
 doi = {10.1007/978-3-030-05318-5},
 file = {Hutter, Kotthoff et al 2019 - Automated Machine Learning:Attachments/Hutter, Kotthoff et al 2019 - Automated Machine Learning.pdf:application/pdf}
}


@book{ISO1,
 author = {{ISO - INTERNATIONAL STANDARD}},
 year = {2019},
 title = {ISO 6336-6:2019(E): Calculation of load capacity of spur and helical gears: Part 6: Calculation of service life under variable load},
 publisher = {ISO},
 institution = {{ISO - INTERNATIONAL STANDARD}}
}


@article{Iwana,
 abstract = {In recent times, deep artificial neural networks have achieved many successes in pattern recognition. Part of this success can be attributed to the reliance on big data to increase generalization. However, in the field of time series recognition, many datasets are often very small. One method of addressing this problem is through the use of data augmentation. In this paper, we survey data augmentation techniques for time series and their application to time series classification with neural networks. We propose a taxonomy and outline the four families in time series data augmentation, including transformation-based methods, pattern mixing, generative models, and decomposition methods. Furthermore, we empirically evaluate 12 time series data augmentation methods on 128 time series classification datasets with six different types of neural networks. Through the results, we are able to analyze the characteristics, advantages and disadvantages, and recommendations of each data augmentation method. This survey aims to help in the selection of time series data augmentation for neural network applications.},
 author = {Iwana, Brian Kenji and Uchida, Seiichi},
 year = {2021},
 title = {An empirical survey of data augmentation for time series classification with neural networks},
 url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0254841},
 pages = {e0254841},
 volume = {16},
 number = {7},
 issn = {1932-6203},
 journal = {PLOS ONE},
 doi = {10.1371/journal.pone.0254841},
 file = {Iwana, Uchida 2021 - An empirical survey of data:Attachments/Iwana, Uchida 2021 - An empirical survey of data.pdf:application/pdf}
}


@inproceedings{Jabbar,
 author = {Jabbar, Haider Khalaf and Khan, Rafiqul Zaman},
 title = {Methods to Avoid Over-Fitting and Under-Fitting in Supervised Machine Learning (Comparative Study)},
 publisher = {{Research Publishing Services}},
 booktitle = {Computer Science, Communication and Instrumentation Devices},
 year = {2014},
 address = {Singapore},
 doi = {10.3850/978-981-09-5247-1{\textunderscore }017}
}


@book{Jain,
 year = {1999},
 title = {Recurrent neural networks: Design and applications},
 edition = {0},
 publisher = {{CRC Press}},
 isbn = {9781003040620},
 series = {The CRC Press international series on computational intelligence Recurrent neural networks},
 editor = {Jain, L. C.},
 doi = {10.1201/9781420049176}
}


@article{Janiesch,
 abstract = {Electron Markets, doi:10.1007/s12525-021-00475-2},
 author = {Janiesch, Christian and Zschech, Patrick and Heinrich, Kai},
 year = {2021},
 title = {Machine learning and deep learning},
 keywords = {Analytical model building;Artificial intelligence;Artificial neural networks;C6;C8;Deep Learning;M15;Machine learning;O3},
 pages = {685--695},
 volume = {31},
 number = {3},
 issn = {1019-6781},
 journal = {Electronic Markets},
 doi = {10.1007/s12525-021-00475-2},
 file = {Janiesch, Zschech et al 2021 - Machine learning and deep learning:Attachments/Janiesch, Zschech et al 2021 - Machine learning and deep learning.pdf:application/pdf}
}


@article{JanOveHolmen,
 abstract = {text/javascript},
 author = {{Jan Ove Holmen}},
 year = {1982},
 title = {Fatigue of Concrete by Constant and Variable Amplitude loading},
 pages = {71--110},
 volume = {75},
 journal = {Special Publication},
 doi = {10.14359/6402}
}


@article{Jayalakshmi,
 abstract = {PDF | 89 Abstract--- The artificial neural network has recently been applied in many areas of medical and medically related fields. It is known as an... | Find, read and cite all the research you need on ResearchGate},
 author = {Jayalakshmi, T. and Santhakumaran, A.},
 year = {2011},
 title = {Statistical Normalization and Back Propagationfor Classification},
 url = {https://www.researchgate.net/profile/santhakumaran-a/publication/260024206_statistical_normalization_and_back_propagation_for_clasification},
 pages = {89--93},
 volume = {3},
 number = {1},
 issn = {1793-8201},
 journal = {International Journal of Computer Theory and Engineering},
 doi = {10.7763/IJCTE.2011.V3.288},
 file = {Jayalakshmi, Santhakumaran 2011 - Statistical Normalization and Back Propagationfor:Attachments/Jayalakshmi, Santhakumaran 2011 - Statistical Normalization and Back Propagationfor.pdf:application/pdf}
}


@article{JOOST,
 abstract = {ACM Comput. Surv. 2021.53:1-33},
 author = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
 year = {2021},
 title = {A Survey on Distributed Machine Learning},
 pages = {1--33},
 volume = {53},
 number = {2},
 issn = {0360-0300},
 journal = {ACM Computing Surveys},
 doi = {10.1145/3377454},
 file = {3377454:Attachments/3377454.pdf:application/pdf}
}


@article{Kannojia,
 abstract = {PDF | Image quality is affected by different types of quality factors (such as resolution, noise, contrast, blur, compression). Resolution of the image... | Find, read and cite all the research you need on ResearchGate},
 author = {Kannojia, Suresh Prasad and Jaiswal, Gaurav},
 year = {2018},
 title = {Effects of Varying Resolution on Performance of CNN based Image Classification An Experimental Study},
 url = {https://www.researchgate.net/profile/gaurav-jaiswal-5/publication/328960034_effects_of_varying_resolution_on_performance_of_cnn_based_image_classification_an_experimental_study},
 pages = {451--456},
 volume = {6},
 number = {9},
 issn = {2347-2693},
 journal = {INTERNATIONAL JOURNAL OF COMPUTER SCIENCES AND ENGINEERING},
 doi = {10.26438/ijcse/v6i9.451456}
}


@article{Kara,
 author = {Karabacak, Yunus and {G{\"u}rsel {\"O}zmen}, Nurhan and G{\"u}m{\"u}{\c{s}}el, Levent},
 year = {2020},
 title = {Worm gear condition monitoring and fault detection from thermal images via deep learning method},
 pages = {544--556},
 volume = {22},
 number = {3},
 issn = {1507-2711},
 journal = {Eksploatacja i Niezawodno{\'s}{\'c} -- Maintenance and Reliability},
 doi = {10.17531/ein.2020.3.18},
 file = {Karabacak, G{\"u}rsel {\"O}zmen et al. 2020 - Worm gear condition monitoring:Attachments/Karabacak, G{\"u}rsel {\"O}zmen et al. 2020 - Worm gear condition monitoring.pdf:application/pdf}
}


@article{KaraACUSTIC,
 author = {Karabacak, Yunus Emre and {G{\"u}rsel {\"O}zmen}, Nurhan},
 year = {2022},
 title = {Common spatial pattern-based feature extraction and worm gear fault detection through vibration and acoustic measurements},
 url = {https://www.sciencedirect.com/science/article/pii/s0263224121012604},
 pages = {110366},
 volume = {187},
 issn = {0263-2241},
 journal = {Measurement},
 doi = {10.1016/j.measurement.2021.110366}
}


@article{Karniadakis,
 abstract = {Nature Reviews Physics, doi:10.1038/s42254-021-00314-5},
 author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
 year = {2021},
 title = {Physics-informed machine learning},
 pages = {422--440},
 volume = {3},
 number = {6},
 journal = {Nature Reviews Physics},
 doi = {10.1038/s42254-021-00314-5},
 file = {Karniadakis, Kevrekidis et al 2021 - Physics-informed machine learning:Attachments/Karniadakis, Kevrekidis et al 2021 - Physics-informed machine learning.pdf:application/pdf}
}


@incollection{Klein,
 abstract = {Viele im Stahlbau sowie alle im Fahrzeugbau und in der Luft- und Raumfahrt eingesetzten Konstruktionen werden dynamisch beansprucht. Wenn hierbei durch ein m{\"o}gliches Versagen folgenreiche Sch{\"a}den entstehen k{\"o}nnen, kommt dem Aspekt der...},
 author = {Klein, Bernd and G{\"a}nsicke, Thomas},
 title = {Schwingbeanspruchte Strukturen},
 url = {https://link.springer.com/chapter/10.1007/978-3-658-26846-6_24},
 pages = {387--424},
 publisher = {{Springer Vieweg, Wiesbaden}},
 booktitle = {Leichtbau-Konstruktion},
 year = {2019},
 doi = {10.1007/978-3-658-26846-6{\textunderscore }24},
 file = {Klein, G{\"a}nsicke 2019 - Schwingbeanspruchte Strukturen:Attachments/Klein, G{\"a}nsicke 2019 - Schwingbeanspruchte Strukturen.pdf:application/pdf}
}


@article{LeCun,
 abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
 author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
 year = {2015},
 title = {Deep learning},
 url = {https://www.nature.com/articles/nature14539},
 pages = {436--444},
 volume = {521},
 number = {7553},
 issn = {1476-4687},
 journal = {Nature},
 doi = {10.1038/nature14539},
 file = {LeCun, Bengio et al 2015 - Deep learning:Attachments/LeCun, Bengio et al 2015 - Deep learning.pdf:application/pdf}
}


@book{Lee,
 abstract = {Fatigue Testing and Analysis: Theory and Practice presents the latest, proven techniques for fatigue data acquisition, data analysis, and test planning and practice. More specifically, it covers the most comprehensive methods to capture the component load, to characterize the scatter of product fatigue resistance and loading, to perform the fatigue damage assessment of a product, and to develop an accelerated life test plan for reliability target demonstration. This book is most useful for test and design engineers in the ground vehicle industry.Fatigue Testing and~Analysis introduces the meth},
 author = {Lee, Yung-Li},
 year = {2011},
 title = {Fatigue Testing and  Analysis: Theory and Practice},
 address = {Burlington},
 publisher = {{Elsevier Science}},
 isbn = {9780750677196}
}


@article{LEX,
 author = {{Amiri, Roohollah and Mehrpouyan, Hani and Fridman, Lex and Mallik, Ranjan and Nallanathan, Arumugam and Matolak, David}},
 year = {2018},
 title = {A Machine Learning Approach for Power Allocation in HetNets Considering QoS},
 file = {Amiri, Roohollah and Mehrpouyan, Hani and Fridman, Lex and Mallik, Ranjan and Nallanathan, Arumugam:Attachments/Amiri, Roohollah and Mehrpouyan, Hani and Fridman, Lex and Mallik, Ranjan and Nallanathan, Arumugam.pdf:application/pdf}
}


@article{Li,
 abstract = {Multispectral imaging (MSI) was implemented to develop a burn tissue classification device to assist burn surgeons in planning and performing debridement surgery. To build a classification model via machine learning, training data accurately representing the burn tissue was needed, but assigning raw MSI data to appropriate tissue classes is prone to error. We hypothesized that removing outliers from the training dataset would improve classification accuracy. A swine burn model was developed to build an MSI training database and study an algorithm's burn tissue classification abilities. After the ground-truth database was generated, we developed a multistage method based on Z -test and univariate analysis to detect and remove outliers from the training dataset. Using 10-fold cross validation, we compared the algorithm's accuracy when trained with and without the presence of outliers. The outlier detection and removal method reduced the variance of the training data. Test accuracy was improved from 63{\%} to 76{\%}, matching the accuracy of clinical judgment of expert burn surgeons, the current gold standard in burn injury assessment. Given that there are few surgeons and facilities specializing in burn care, this technology may improve the standard of burn care for patients without access to specialized facilities.},
 author = {Li, Weizhi and Mo, Weirong and Zhang, Xu and Squiers, John J. and Lu, Yang and Sellke, Eric W. and Fan, Wensheng and DiMaio, J. Michael and Thatcher, Jeffrey E.},
 year = {2015},
 title = {Outlier detection and removal improves accuracy of machine learning approach to multispectral burn diagnostic imaging},
 url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-20/issue-12/121305/outlier-detection-and-removal-improves-accuracy-of-machine-learning-approach/10.1117/1.jbo.20.12.121305.short},
 pages = {121305},
 volume = {20},
 number = {12},
 issn = {1560-2281},
 journal = {Journal of Biomedical Optics},
 doi = {10.1117/1.JBO.20.12.121305},
 file = {Li, Mo et al. 2015 - Outlier detection and removal improves:Attachments/Li, Mo et al. 2015 - Outlier detection and removal improves.pdf:application/pdf}
}


@book{Little,
 author = {Little, Robert Eugene and Ekvall, J. C.},
 year = {1981},
 title = {Statistical Analysis of Fatigue Data: A Symposium},
 publisher = {{ASTM International}}
}


@article{Lu,
 author = {Lu, Siliang and Lu, Jinfeng and An, Kang and Wang, Xiaoxian and He, Qingbo},
 year = {2023},
 title = {Edge Computing on IoT for Machine Signal Processing and Fault Diagnosis: A Review},
 pages = {1},
 issn = {2327-4662},
 journal = {IEEE Internet of Things Journal},
 doi = {10.1109/jiot.2023.3239944},
 file = {Lu, Lu et al. 2023 - Edge Computing on IoT:Attachments/Lu, Lu et al. 2023 - Edge Computing on IoT.pdf:application/pdf}
}


@article{Luo,
 abstract = {Machine learning studies automatic algorithms that improve themselves through experience. It is widely used for analyzing and extracting value from large biomedical data sets, or ``big biomedical data,'' advancing biomedical research, and improving healthcare. Before a machine learning model is trained, the user of a machine learning software tool typically must manually select a machine learning algorithm and set one or more model parameters termed hyper-parameters. The algorithm and hyper-parameter values used can greatly impact the resulting model's performance, but their selection requires special expertise as well as many labor-intensive manual iterations. To make machine learning accessible to layman users with limited computing expertise, computer science researchers have proposed various automatic selection methods for algorithms and/or hyper-parameter values for a given supervised machine learning problem. This paper reviews these methods, identifies several of their limitations in the big biomedical data environment, and provides preliminary thoughts on how to address these limitations. These findings establish a foundation for future research on automatically selecting algorithms and hyper-parameter values for analyzing big biomedical data.},
 author = {Luo, Gang},
 year = {2016},
 title = {A review of automatic selection methods for machine learning algorithms and hyper-parameter values},
 url = {https://link.springer.com/article/10.1007/s13721-016-0125-6},
 pages = {1--16},
 volume = {5},
 number = {1},
 issn = {2192-6670},
 journal = {Network Modeling Analysis in Health Informatics and Bioinformatics},
 doi = {10.1007/s13721-016-0125-6},
 file = {Luo 2016 - A review of automatic selection:Attachments/Luo 2016 - A review of automatic selection.pdf:application/pdf}
}


@article{Lv,
 author = {Lv, Zhiqiang and Huang, Hong-Zhong and Zhu, Shun-Peng and Gao, Huiying and Zuo, Fangjun},
 year = {2015},
 title = {A modified nonlinear fatigue damage accumulation model},
 pages = {168--181},
 volume = {24},
 number = {2},
 issn = {1056-7895},
 journal = {International Journal of Damage Mechanics},
 doi = {10.1177/1056789514524075}
}


@article{Lyu,
 author = {Lyu, Yecheng and Bai, Lin and Huang, Xinming},
 year = {2019},
 title = {ChipNet: Real-Time LiDAR Processing for Drivable Region Segmentation on an FPGA},
 pages = {1769--1779},
 volume = {66},
 number = {5},
 issn = {1549-8328},
 journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
 doi = {10.1109/TCSI.2018.2881162},
 file = {Lyu, Bai et al 2019 - ChipNet Real-Time LiDAR Processing:Attachments/Lyu, Bai et al 2019 - ChipNet Real-Time LiDAR Processing.pdf:application/pdf}
}


@article{Mahakul.2021,
 author = {Mahakul, Rounak and {Nath Thatoi}, Dhirendra and Choudhury, Sasanka and Patnaik, Pragyan},
 year = {2021},
 title = {Design and numerical analysis of spur gear using SolidWorks simulation technique},
 url = {https://www.sciencedirect.com/science/article/pii/s2214785320372709},
 pages = {340--346},
 volume = {41},
 issn = {2214-7853},
 journal = {Materials Today: Proceedings},
 doi = {10.1016/j.matpr.2020.09.554}
}


@article{Mahesh,
 abstract = {Computer Engineering},
 author = {Mahesh, Batta},
 year = {2019},
 title = {Machine Learning Algorithms - A Review},
 url = {DOI: 10.21275/ART20203995},
 keywords = {Algorithm;Machine learning;Pseudo Code;Reinforcement learning;Supervised learning;Unsupervised learning},
 file = {Mahesh 2019 - Machine Learning Algorithms:Attachments/Mahesh 2019 - Machine Learning Algorithms.pdf:application/pdf}
}


@inproceedings{Medina,
 author = {Medina, Ruben and Cerrada, Mariela and Cabrera, Diego and Sanchez, Rene-Vinicio and Li, Chuan and de Oliveira, Jose Valente},
 title = {Deep Learning-Based Gear Pitting Severity Assessment Using Acoustic Emission, Vibration and Currents Signals},
 publisher = {IEEE},
 booktitle = {2019 Prognostics and System Health Management Conference (PHM-Paris)},
 year = {2019},
 doi = {10.1109/phm-paris.2019.00042}
}


@inproceedings{Mikolajczyk,
 author = {Mikolajczyk, Agnieszka and Grochowski, Michal},
 title = {Data augmentation for improving deep learning in image classification problem},
 publisher = {IEEE},
 booktitle = {2018 International Interdisciplinary PhD Workshop (IIPhDW)},
 year = {2018},
 doi = {10.1109/iiphdw.2018.8388338},
 file = {Mikolajczyk, Grochowski 2018 - Data augmentation for improving deep:Attachments/Mikolajczyk, Grochowski 2018 - Data augmentation for improving deep.pdf:application/pdf}
}


@inproceedings{Mikolajczyk.2018,
 author = {Mikolajczyk, Agnieszka and Grochowski, Michal},
 title = {Data augmentation for improving deep learning in image classification problem},
 publisher = {IEEE},
 booktitle = {2018 International Interdisciplinary PhD Workshop (IIPhDW)},
 year = {2018},
 doi = {10.1109/iiphdw.2018.8388338}
}


@article{Miller,
 author = {Miller, K. J. and Zachariah, K. P.},
 year = {1977},
 title = {Cumulative damage laws for fatigue crack initiation and stage i propagation},
 pages = {262--270},
 volume = {12},
 number = {4},
 issn = {0309-3247},
 journal = {The Journal of Strain Analysis for Engineering Design},
 doi = {10.1243/03093247v124262}
}


@article{MinerOG,
 author = {Miner, Milton A.},
 year = {1945},
 title = {Cumulative Damage in Fatigue},
 pages = {A159-A164},
 volume = {12},
 number = {3},
 issn = {0021-8936},
 journal = {Journal of Applied Mechanics},
 doi = {10.1115/1.4009458}
}


@article{Minsky,
 author = {Minsky, Marvin},
 year = {1961},
 title = {Steps toward artificial intelligence},
 url = {https://courses.csail.mit.edu/6.803/pdf/steps.pdf},
 pages = {8--30},
 number = {1},
 journal = {Proceedings of the IRE},
 file = {Minsky 1961 - Steps toward artificial intelligence:Attachments/Minsky 1961 - Steps toward artificial intelligence.pdf:application/pdf}
}


@inproceedings{Misyris,
 author = {Misyris, George S. and Venzke, Andreas and Chatzivasileiadis, Spyros},
 title = {Physics-Informed Neural Networks for Power Systems},
 publisher = {IEEE},
 booktitle = {2020 IEEE Power {\&} Energy Society General Meeting (PESGM)},
 year = {2020},
 doi = {10.1109/pesgm41954.2020.9282004},
 file = {Misyris, Venzke et al. 2020 - Physics-Informed Neural Networks for Power:Attachments/Misyris, Venzke et al. 2020 - Physics-Informed Neural Networks for Power.pdf:application/pdf}
}


@book{Mobley,
 abstract = {This second edition of An Introduction to Predictive Maintenance helps plant, process, maintenance and reliability managers and engineers to develop and implement a comprehensive maintenance management program, providing proven strategies for regularly monitoring critical process equipment and systems, predicting machine failures, and scheduling maintenance accordingly. Since the publication of the first edition in 1990, there have been many changes in both technology and methodology, including financial implications, the role of a maintenance organization, predictive maintenance techniques, various analyses, and maintenance of the program itself. This revision includes a complete update of the applicable chapters from the first edition as well as six additional chapters outlining the most recent information available. Having already been implemented and maintained successfully in hundreds of manufacturing and process plants worldwide, the practices detailed in this second edition of An Introduction to Predictive Maintenance will save plants and corporations, as well as U.S. industry as a whole, billions of dollars by minimizing unexpected equipment failures and its resultant high maintenance cost while increasing productivity. * A comprehensive introduction to a system of monitoring critical industrial equipment * Optimize the availability of process machinery and greatly reduce the cost of maintenance * Provides the means to improve product quality, productivity and profitability of manufacturing and production plants.



Front Cover -- AN INTRODUCTION TO PREDICTIVE MAINTENANCE -- Copyright Page -- Contents -- Chapter 1. Impact of Maintenance -- 1.1 Maintenance Management Methods -- 1.2 Optimizing Predictive Maintenance -- Chapter 2. Financial Implications and Cost Justification -- 2.1 Assessing the Need for Condition Monitoring -- 2.2 Cost Justification -- 2.3 Justifying Predictive Maintenance -- 2.4 Economics of Preventive Maintenance -- Chapter 3. Role of Maintenance Organization -- 3.1 Maintenance Mission -- 3.2 Evaluation of the Maintenance Organization -- 3.3 Designing a Predictive Maintenance Program -- Chapter 4. Benefits of Predictive Maintenance -- 4.1 Primary Uses of Predictive Maintenance -- Chapter 5. Machine-Train Monitoring Parameters -- 5.1 Drivers -- 5.2 Intermediate Drives -- 5.3 Driven Components -- Chapter 6. Predictive Maintenance Techniques -- 6.1 Vibration Monitoring -- 6.2 Thermography -- 6.3 Tribology -- 6.4 Visual Inspections -- 6.5 Ultrasonics -- 6.6 Other Techniques -- Chapter 7. Vibration Monitoring and Analysis -- 7.1 Vibration Analysis Applications -- 7.2 Vibration Analysis Overview -- 7.3 Vibration Sources -- 7.4 Vibration Theory -- 7.5 Machine Dynamics -- 7.6 Vibration Data Types and Formats -- 7.7 Data Acquisition -- 7.8 Vibration Analyses Techniques -- Appendix 7.1 Abbreviations -- Appendix 7.2 Glossary -- Appendix 7.3 References -- Chapter 8. Thermography -- 8.1 Infrared Basics -- 8.2 Types of Infrared Instruments -- 8.3 Training -- 8.4 Basic Infrared Theory -- 8.5 Infrared Equipment -- 8.6 Infrared Thermography Safety -- 8.7 Infrared Scanning Procedures -- 8.8 Types of Infrared Problems -- Appendix 8.1 Abbreviations -- Appendix 8.2 Glossary -- Appendix 8.3 Electrical Terminology -- Appendix 8.4 Materials List -- Chapter 9. Tribology -- 9.1 Lubricating Oil Analysis -- 9.2 Setting Up an Effective Program.},
 author = {Mobley, R. Keith},
 year = {2002},
 title = {Introduction to Predictive Maintenance},
 address = {Oxford},
 edition = {2nd ed.},
 publisher = {{Elsevier Science {\&} Technology}},
 isbn = {9780080478692},
 series = {Plant Engineering Ser}
}


@book{Molnar,
 abstract = {www.dbooks.org},
 author = {Molnar, Christoph},
 year = {2022},
 title = {Interpretable machine learning: A guide for making black box models explainable},
 keywords = {www.dbooks.org},
 address = {Munich, Germany},
 edition = {Second edition},
 publisher = {{Christoph Molnar}},
 isbn = {979-8411463330},
 file = {Molnar 2022 - Interpretable machine learning:Attachments/Molnar 2022 - Interpretable machine learning.pdf:application/pdf}
}


@book{Murphy,
 abstract = {{\textquotedbl}This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online{\textquotedbl}--Back cover},
 author = {Murphy, Kevin P.},
 year = {2012},
 title = {Machine learning: A probabilistic perspective},
 address = {Cambridge, Mass.},
 publisher = {{MIT Press}},
 isbn = {978-0262018029},
 series = {Adaptive computation and machine learning series},
 file = {Murphy 2012 - Machine learning:Attachments/Murphy 2012 - Machine learning.pdf:application/pdf}
}


@article{Muzaffar,
 author = {Muzaffar, Shahzad and Afshari, Afshin},
 year = {2019},
 title = {Short-Term Load Forecasts Using LSTM Networks},
 url = {https://www.sciencedirect.com/science/article/pii/s1876610219310008},
 pages = {2922--2927},
 volume = {158},
 issn = {1876-6102},
 journal = {Energy Procedia},
 doi = {10.1016/j.egypro.2019.01.952}
}


@article{Park,
 author = {Park, Ju-Youn and Hwang, Yewon and Lee, Dukyoung and Kim, Jong-Hwan},
 year = {2020},
 title = {MarsNet: Multi-Label Classification Network for Images of Various Sizes},
 pages = {21832--21846},
 volume = {8},
 issn = {2169-3536},
 journal = {IEEE Access},
 doi = {10.1109/access.2020.2969217},
 file = {Park, Hwang et al. 2020 - MarsNet Multi-Label Classification Network:Attachments/Park, Hwang et al. 2020 - MarsNet Multi-Label Classification Network.pdf:application/pdf}
}


@article{Pavlo,
 abstract = {Impact of Training Set Batch Size on the Performance of Convolutional Neural Networks for Diverse Datasets},
 author = {{Pavlo M. Radiuk}},
 year = {2017},
 title = {Impact of Training Set Batch Size on the Performance of Convolutional Neural Networks for Diverse Datasets},
 url = {https://itms-journals.rtu.lv/article/view/itms-2017-0003},
 pages = {20--24},
 volume = {20},
 number = {1},
 issn = {2255-9094},
 journal = {Information Technology and Management Science},
 file = {Pavlo M. Radiuk 2017 - Impact of Training Set Batch:Attachments/Pavlo M. Radiuk 2017 - Impact of Training Set Batch.pdf:application/pdf}
}


@article{Pavlou,
 author = {Pavlou, Dimitrios G.},
 year = {2018},
 title = {The theory of the S-N fatigue damage envelope: Generalization of linear, double-linear, and non-linear fatigue damage models},
 url = {https://www.sciencedirect.com/science/article/pii/s014211231830029x},
 pages = {204--214},
 volume = {110},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2018.01.023}
}


@book{Peshawa,
 abstract = {PDF | This paper aims to clarify how and why data are normalized or standardized, these two processes are used in the data preprocessing stage in which... | Find, read and cite all the research you need on ResearchGate},
 author = {{Peshawa J Muhammad Ali} and {Rezhna Hassan Faraj}},
 year = {2014},
 title = {Data Normalization and Standardization: A Technical Report},
 url = {https://www.researchgate.net/profile/peshawa-muhammad-ali/publication/340579135_data_normalization_and_standardization_a_technical_report},
 publisher = {Unpublished},
 doi = {10.13140/RG.2.2.28948.04489},
 file = {Peshawa J Muhammad Ali, Rezhna Hassan Faraj 2014 - Data Normalization and Standardization:Attachments/Peshawa J Muhammad Ali, Rezhna Hassan Faraj 2014 - Data Normalization and Standardization.pdf:application/pdf}
}


@book{Philipp,
 author = {{Philipp Probst, Anne-Laure Boulesteix, Bernd Bischl}},
 year = {2019},
 title = {Tunability: Importance of hyperparameters of machine learning algorithms},
 url = {https://www.jmlr.org/papers/volume20/18-444/18-444.pdf},
 institution = {{Journal of Machine Learning Research}},
 file = {Tunability 2019:Attachments/Tunability 2019.pdf:application/pdf}
}


@article{Pramila,
 abstract = {2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA);2018; ; ;},
 author = {{Pramila P. Shinde} and {Seema Shah}},
 year = {2018},
 title = {2018 Fourth International Conference on Computing, Communication, Control and Automation (ICCUBEA): 16th to 18th August, 2018 : proceedings},
 url = {https://ieeexplore.ieee.org/servlet/opac?punumber=8681925},
 keywords = {Deep Learning;Frameworks;Machine learning},
 file = {Pramila P Shinde, Seema Shah 2018 - 2018 Fourth International Conference:Attachments/Pramila P Shinde, Seema Shah 2018 - 2018 Fourth International Conference.pdf:application/pdf}
}


@article{Prav,
 author = {Praveenkumar, T. and Saimurugan, M. and Krishnakumar, P. and Ramachandran, K. I.},
 year = {2014},
 title = {Fault Diagnosis of Automobile Gearbox Based on Machine Learning Techniques},
 url = {https://www.sciencedirect.com/science/article/pii/s187770581403522x},
 pages = {2092--2098},
 volume = {97},
 issn = {1877-7058},
 journal = {Procedia Engineering},
 doi = {10.1016/j.proeng.2014.12.452}
}


@article{Praveenkumar.2014,
 author = {Praveenkumar, T. and Saimurugan, M. and Krishnakumar, P. and Ramachandran, K. I.},
 year = {2014},
 title = {Fault Diagnosis of Automobile Gearbox Based on Machine Learning Techniques},
 url = {https://www.sciencedirect.com/science/article/pii/s187770581403522x},
 pages = {2092--2098},
 volume = {97},
 issn = {1877-7058},
 journal = {Procedia Engineering},
 doi = {10.1016/j.proeng.2014.12.452}
}


@article{Pungo,
 author = {Pungo, N. and CIAVARELLA, M. and CORNETTI, P. and CARPINTERI, A.},
 year = {2006},
 title = {A generalized Paris' law for fatigue crack growth},
 url = {https://www.sciencedirect.com/science/article/pii/s0022509606000196},
 pages = {1333--1349},
 volume = {54},
 number = {7},
 issn = {0022-5096},
 journal = {Journal of the Mechanics and Physics of Solids},
 doi = {10.1016/j.jmps.2006.01.007}
}


@inproceedings{Raju,
 author = {Raju, V. N. Ganapathi and Lakshmi, K. Prasanna and Jain, Vinod Mahesh and Kalidindi, Archana and Padma, V.},
 title = {Study the Influence of Normalization/Transformation process on the Accuracy of Supervised Classification},
 publisher = {IEEE},
 booktitle = {2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)},
 year = {2020},
 doi = {10.1109/icssit48917.2020.9214160}
}


@book{Rao,
 abstract = {Hardbound. The need to reduce costs has generated a greater interest in condition monitoring in recent years. The Handbook of Condition Monitoring gives an extensive description of available products and their usage making it a source of practical guidance supported by basic theory.This handbook has been designed to assist individuals within companies in the methods and devices used to monitor the condition of machinery and products.},
 author = {Rao, B. K. N.},
 year = {1996},
 title = {Handbook of condition monitoring},
 address = {Oxford},
 edition = {1. ed.},
 publisher = {{Elsevier Advanced Technology}},
 isbn = {9781856172349}
}


@article{Rege,
 author = {Rege, Kristen and Pavlou, Dimitrios G.},
 year = {2017},
 title = {A one-parameter nonlinear fatigue damage accumulation model},
 url = {https://www.sciencedirect.com/science/article/pii/s014211231730049x},
 pages = {234--246},
 volume = {98},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2017.01.039}
}


@book{RTiwari,
 abstract = {PDF | The omnipresence of gears as critical elements in complex rotating machinery has made the study of vibration a more interesting subject. One of... | Find, read and cite all the research you need on ResearchGate},
 author = {Tiwari and {N Tanwar} and {S Mishra}},
 year = {2009},
 title = {APPLICATION OF SUPPORT VECTOR MACHINE TECHNIQUES FOR HEALTH MONITORING OF GEARS},
 url = {https://www.researchgate.net/profile/rajiv-tiwari/publication/357418196_application_of_support_vector_machine_techniques_for_health_monitoring_of_gears},
 publisher = {{Condition Monitoring Society of India}},
 institution = {{Department of Mechanical Engineering, Indian Institute of Technology Guwahati}},
 file = {R Tiwari, N Tanwar et al. 2021 - APPLICATION OF SUPPORT VECTOR MACHINE:Attachments/R Tiwari, N Tanwar et al. 2021 - APPLICATION OF SUPPORT VECTOR MACHINE.pdf:application/pdf}
}


@book{Russell,
 abstract = {From the Publisher: The long-anticipated revision of this number 1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications.  Intelligent Agents.  Solving Problems by Searching. Informed Search Methods.  Game Playing.  Agents that Reason Logically.  First-order Logic.  Building a Knowledge Base.  Inference in First-Order Logic.  Logical Reasoning Systems.  Practical Planning.  Planning and Acting.  Uncertainty.  Probabilistic Reasoning Systems.  Making Simple Decisions.  Making Complex Decisions. Learning from Observations.  Learning with Neural Networks.  Reinforcement Learning.  Knowledge in Learning.  Agents that Communicate.  Practical Communication in English.  Perception.  Robotics.  For computer professionals, linguists, and cognitive scientists interested in artificial intelligence},
 author = {{Stuart J. Russell, Peter Norvig} and Russell, Stuart J. and Norvig, Peter},
 year = {2010},
 title = {Artificial Intelligence - A Modern Approach // Artificial intelligence: A modern approach: Third Edition},
 address = {Upper Saddle River, NJ},
 edition = {3. ed.},
 publisher = {Prentice-Hall},
 isbn = {978-0-13-604259-4},
 series = {Prentice-Hall series in artificial intelligence},
 doi = {Stuart},
 file = {Stuart J Russell, Peter Norvig, Russell et al 2010 - Artificial Intelligence:Attachments/Stuart J Russell, Peter Norvig, Russell et al 2010 - Artificial Intelligence.pdf:application/pdf}
}


@book{Sainath,
 author = {Sainath, Tara N. and Vinyals, Oriol and Senior, Andrew and Sak, Hasim},
 year = {2015},
 title = {Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks},
 doi = {10.1109/icassp.2015.7178838},
 file = {Sainath, Vinyals et al. 2015 - Convolutional:Attachments/Sainath, Vinyals et al. 2015 - Convolutional.pdf:application/pdf}
}


@article{Salehinejad,
 author = {{Salehinejad, Hojjat and Sankar, Sharan and Barfett, Joseph and Colak, Errol and Valaee, Shahrokh}},
 year = {2017},
 title = {Recent advances in recurrent neural networks},
 url = {https://arxiv.org/pdf/1801.01078.pdf},
 file = {638204646713444448:Attachments/638204646713444448.pdf:application/pdf}
}


@book{Sander,
 author = {Sander, Manuela},
 year = {2018},
 title = {Sicherheit und Betriebsfestigkeit von Maschinen und Anlagen: Konzepte und Methoden zur Lebensdauervorhersage},
 price = {Festeinband : ca. EUR 70.00},
 address = {Berlin, Germany and Heidelberg},
 edition = {2., aktualisierte und erg{\"a}nzte Auflage},
 publisher = {{Springer Vieweg}},
 isbn = {9783662544426},
 doi = {10.1007/978-3-662-54443-3},
 file = {Sander 2018 - Sicherheit und Betriebsfestigkeit von Maschinen:Attachments/Sander 2018 - Sicherheit und Betriebsfestigkeit von Maschinen.pdf:application/pdf}
}


@article{Shorten,
 author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
 year = {2019},
 title = {A survey on Image Data Augmentation for Deep Learning},
 volume = {6},
 number = {1},
 issn = {2196-1115},
 journal = {Journal of big data},
 doi = {10.1186/s40537-019-0197-0},
 file = {Shorten, Khoshgoftaar 2019 - A survey on Image Data:Attachments/Shorten, Khoshgoftaar 2019 - A survey on Image Data.pdf:application/pdf}
}


@article{Singh,
 author = {Singh, Dalwinder and Singh, Birmohan},
 year = {2020},
 title = {Investigating the impact of data normalization on classification performance},
 url = {https://www.sciencedirect.com/science/article/pii/s1568494619302947},
 pages = {105524},
 volume = {97},
 issn = {1568-4946},
 journal = {Applied Soft Computing},
 doi = {10.1016/j.asoc.2019.105524},
 file = {Singh, Singh 2020 - Investigating the impact of data:Attachments/Singh, Singh 2020 - Investigating the impact of data.pdf:application/pdf}
}


@book{Skansi,
 author = {Skansi, Sandro},
 year = {2018},
 title = {Introduction to deep learning: From logical calculus to artificial intelligence},
 address = {Cham, Switzerland},
 publisher = {Springer},
 isbn = {978-3-319-73003-5},
 series = {Undergraduate topics in computer science},
 file = {Skansi 2018 - Introduction to deep learning:Attachments/Skansi 2018 - Introduction to deep learning.pdf:application/pdf}
}


@misc{SKlearn,
 author = {scikit},
 year = {2023},
 title = {scikit-learn: machine learning in Python --- scikit-learn 1.2.2 documentation, Access date: 25/06/2023},
 url = {https://scikit-learn.org/stable/index.html}
}


@article{Skorupa,
 abstract = {The current understanding of the underlying reasons behind the load interaction effects in fatigue crack growth under variable amplitude loading is presented. Mechanistic arguments proposed to cont...},
 author = {Skorupa, M.},
 year = {1999},
 title = {Load interaction effects during fatigue crack growth under variable amplitude loading-a literature review. Part II: qualitative interpretation},
 pages = {905--926},
 volume = {22},
 number = {10},
 issn = {1460-2695},
 journal = {Fatigue {\&} Fracture of Engineering Materials {\&} Structures},
 doi = {10.1046/j.1460-2695.1999.00158.x},
 file = {Skorupa 1999 - Load interaction effects during fatigue:Attachments/Skorupa 1999 - Load interaction effects during fatigue.pdf:application/pdf}
}


@misc{SOLID,
 author = {SOLIDWORKS},
 year = {2023},
 title = {Derivation of Basquin Constants from S-N curve - 2020 - SOLIDWORKS Help (Access Date: 19/06/2023)},
 url = {https://help.solidworks.com/2020/english/SolidWorks/cworks/r_Calculation_Basquin_Constants_S-N_curve.htm}
}


@book{Staudemeyer,
 abstract = {Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the most powerful dynamic classifiers publicly known. The network itself and the related learning algorithms are reasonably well documented to get an idea how it works. This paper will shed more light into understanding how LSTM-RNNs evolved and why they work impressively well, focusing on the early, ground-breaking publications. We significantly improved documentation and fixed a number of errors and inconsistencies that accumulated in previous publications. To support understanding we as well revised and unified the notation used.},
 author = {Staudemeyer, Ralf C. and Morris, Eric Rothstein},
 year = {2019},
 title = {Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent  Neural Networks},
 file = {Staudemeyer, Morris 2019 - Understanding LSTM - a tutorial:Attachments/Staudemeyer, Morris 2019 - Understanding LSTM - a tutorial.pdf:application/pdf}
}


@misc{STBT,
 author = {{Symbrium | An Engineer's Engineering Company}},
 year = {2023},
 title = {Symbrium Single Tooth Bending Gear Testing Systems: Access date: 17.06.2023},
 url = {https://www.symbrium.com/symbrium-single-tooth-bending-gear-testing-systems/}
}


@article{Subramanyan,
 abstract = {Making use of a set of isodamage lines, a fresh concept for predicting the fatigue life, under variable amplitude loading, is presented. It is assumed that all isodamage lines converge at the knee point of a S-log N diagram. The life predictions based on this concept are closer to the experimental data than given by Miner's linear damage rule. The concept is verified with the step-test data obtained on unnotched C-35 steel specimens in rotary bending. Several other reported experimental data in rotary bending tests also confirm the reliability of this simple damage rule.},
 author = {Subramanyan, S.},
 year = {1976},
 title = {A Cumulative Damage Rule Based on the Knee Point of the S-N Curve},
 pages = {316--321},
 volume = {98},
 number = {4},
 issn = {0094-4289},
 journal = {Journal of Engineering Materials and Technology},
 doi = {10.1115/1.3443383}
}


@article{Sun,
 author = {Sun, Qin and Dui, Hong-Na and Fan, Xue-Ling},
 year = {2014},
 title = {A statistically consistent fatigue damage model based on Miner's rule},
 url = {https://www.sciencedirect.com/science/article/pii/s0142112313001047},
 pages = {16--21},
 volume = {69},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2013.04.006}
}


@book{Sutton,
 abstract = {{\textquotedbl}Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms.{\textquotedbl}--},
 author = {Sutton, Richard S. and Barto, Andrew},
 year = {2020},
 title = {Reinforcement learning: An introduction},
 price = {Hardcover : GBP 62.00, USD 80.00},
 address = {Cambridge, Massachusetts and London, England},
 edition = {Second edition},
 publisher = {{The MIT Press}},
 isbn = {9780262039246},
 series = {Adaptive computation and machine learning},
 file = {Sutton, Barto 2020 - Reinforcement learning:Attachments/Sutton, Barto 2020 - Reinforcement learning.pdf:application/pdf}
}


@book{Takuma,
 author = {{Takuma Seno}, Michita Imai},
 year = {2022},
 title = {d3rlpy: An Offline Deep Reinforcement Learning Library},
 url = {https://arxiv.org/pdf/2111.03788.pdf},
 publisher = {{Journal of Machine Learning Research 23}},
 file = {Takuma Seno 2022 - d3rlpy An Offline Deep Reinforcement:Attachments/Takuma Seno 2022 - d3rlpy An Offline Deep Reinforcement.pdf:application/pdf}
}


@inproceedings{Taylor,
 author = {Taylor, Luke and Nitschke, Geoff},
 title = {Improving Deep Learning with Generic Data Augmentation},
 publisher = {IEEE},
 booktitle = {2018 IEEE Symposium Series on Computational Intelligence (SSCI)},
 year = {2018},
 doi = {10.1109/ssci.2018.8628742},
 file = {Taylor, Nitschke 2018 - Improving Deep Learning with Generic:Attachments/Taylor, Nitschke 2018 - Improving Deep Learning with Generic.pdf:application/pdf}
}


@book{Theodoridis,
 abstract = {This tutorial text gives a unifying perspective on machine learning by covering both~probabilistic and deterministic approaches -which are based on optimization techniques - together with the Bayesian inference approach, whose essence lies~in the use of a hierarchy of probabilistic models.  The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts.The book builds carefully from the basic classical methods~ to ~the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for ~different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models.All major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods.The latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling.Case studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied.MATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code. Sergios Theodoridis is Professor of Signal Processing and Machine Learning in the Department of Informatics and Telecommunications of the University of Athens.  He is the co-author of the bestselling book, Pattern Recognition, and the co-author of Introduction to Pattern Recognition: A MATLAB Approach.  He serves as Editor-in-Chief for the IEEE Transactions on Signal Processing, and he is the co-Editor in Chief with Rama Chellapa for the Academic  Press Library in Signal Processing.  He has received a number of awards including the 2014 IEEE Signal Processing Magazine Best Paper Award, the 2009 IEEE Computational Intelligence Society Transactions on Neural Networks Outstanding Paper Award, the 2014 IEEE Signal Processing Society Education Award, the EURASIP 2014 Meritorious Service Award, and he has served as a Distinguished Lecturer for the IEEE Signal Processing Society and the IEEE Circuits and Systems Society. He is a Fellow of EURASIP and a Fellow of IEEE.},
 author = {Theodoridis, Sergios},
 year = {2015},
 title = {Machine Learning: A Bayesian and Optimization Perspective},
 url = {http://gbv.eblib.com/patron/FullRecord.aspx?p=2007481},
 keywords = {Bayesian statistical decision theory;Electronic books;Machine learning;Machine Learning A Bayesian and Optimization Perspective978-0-12-801522-3;Machine learning.;Mathematical optimization;Mathematical optimization.},
 address = {Burlington},
 publisher = {{Elsevier Science}},
 isbn = {9780128015223},
 series = {NET Developers Series},
 file = {Theodoridis 2015 - Machine Learning:Attachments/Theodoridis 2015 - Machine Learning.pdf:application/pdf}
}


@article{Thommandru,
 author = {Thommandru, Abhishek and Mutkule, Prasad and Bandi, Ashalatha and Tongkachok, Korakod},
 year = {2022},
 title = {Towards Applicability of Artificial Intelligence in Healthcare, Banking and Education Sector},
 pages = {16665--16671},
 volume = {107},
 number = {1},
 issn = {1938-5862},
 journal = {ECS Transactions},
 doi = {10.1149/10701.16665ecst}
}


@article{Thompson,
 abstract = {Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image classification, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article catalogs the extent of this dependency, showing that progress across a wide variety of applications is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.},
 author = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
 year = {2020},
 title = {The Computational Limits of Deep Learning},
 url = {https://arxiv.org/pdf/2007.05558},
 file = {Thompson, Greenewald et al. 10 07 2020 - The Computational Limits of Deep:Attachments/Thompson, Greenewald et al. 10 07 2020 - The Computational Limits of Deep.pdf:application/pdf;Thompson, Greenewald et al. 10 07 2020 - The Computational Limits of Deep (2):Attachments/Thompson, Greenewald et al. 10 07 2020 - The Computational Limits of Deep (2).pdf:application/pdf}
}


@misc{tslearn,
 author = {tslearn},
 year = {2023},
 title = {tslearn's documentation --- tslearn 0.5.3.2 documentation, Access date: 25/06/2023},
 url = {https://tslearn.readthedocs.io/en/stable/#}
}


@article{Verbraeken,
 abstract = {ACM Comput. Surv. 2021.53:1-33},
 author = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
 year = {2021},
 title = {A Survey on Distributed Machine Learning},
 pages = {1--33},
 volume = {53},
 number = {2},
 issn = {0360-0300},
 journal = {ACM Computing Surveys},
 doi = {10.1145/3377454},
 file = {Verbraeken, Wolting et al 2021 - A Survey on Distributed Machine:Attachments/Verbraeken, Wolting et al 2021 - A Survey on Distributed Machine.pdf:application/pdf}
}


@article{Vietze,
 abstract = {Most vehicle-gearboxes operating today are designed for a{\&}nbsp;limited service-life. On the one hand, this creates significant potential for decreasing cost and mass as well as reduction of the carbon-footprint. On the other hand, this causes a{\&}nbsp;rising risk of failure with increasing operating time of the machine. Especially if a{\&}nbsp;failure can result in a{\&}nbsp;high economic loss, this fact creates a{\&}nbsp;conflict of goals. On the one hand, the machine should only be maintained or replaced when necessary and, on the other hand, the probability of a{\&}nbsp;failure increases with longer operating times. Therefore, a{\&}nbsp;method is desirable, making it possible to predict the remaining service-life and state of health with as little effort as possible. Centerpiece of gearboxes are the gears. A{\&}nbsp;failure of these components usually causes the whole gearbox to fail. The fatigue life analysis deals with the dimensioning of gears according to the expected loads and the required service-life. Unfortunately, there is very little possibility to validate the technical design during operation, today. Hence, the goal of this paper is to present a{\&}nbsp;method, enabling the prediction of the remaining-service-life and state-of-health of gears during operation. Within this method big-data and machine-learning approaches are used. The method is designed in a{\&}nbsp;way, enabling an easy transfer to other machine elements and kinds of machinery.},
 author = {Vietze, Daniel and Hein, Michael and Stahl, Karsten},
 year = {2020},
 title = {Method for a cloud based remaining-service-life-prediction for vehicle-gearboxes based on big-data-analysis and machine learning},
 url = {https://link.springer.com/article/10.1007/s10010-020-00415-0},
 pages = {305--314},
 volume = {84},
 number = {4},
 issn = {1434-0860},
 journal = {Forschung im Ingenieurwesen},
 doi = {10.1007/s10010-020-00415-0},
 file = {Vietze, Hein et al 2020 - Method for a cloud based:Attachments/Vietze, Hein et al 2020 - Method for a cloud based.pdf:application/pdf}
}


@book{Vogel,
 abstract = {Vorwort des Verlags -- Vorwort zur 2. Auflage -- Inhaltsverzeichnis -- 1 Die Vierte Industrielle Revolution - Der Weg in ein wertschaffendes Produktionsparadigma -- 1 Warum der industrielle Wettbewerb zunimmt und die Welt der Produktion komplex wird -- 1.1 Industrielle Revolutionen der letzten 260 Jahre -- 1.2 Beitrag der Industrie zum Erfolg von Volkswirtschaften -- 1.3 Die Nachfrageseite des Wachstums -- 1.4 Die Angebotsseite des Wachstums -- 1.5 Die Wende der Produktionsfaktoren -- 2 Wie Komplexit{\"a}t von der Fraktalen zur Smarten Fabrik f{\"u}hrt -- 2.1 Komplexit{\"a}tsfelder im Wertsch{\"o}pfungsnetz



2.2 CPS als Basis der Smarten Fabrik -- 2.3 Warum wird das Konzept der Smart Factory Erfolg haben? -- 3 Wie cyber-physische Systeme die Planung und den Betrieb von Fabriken ver{\"a}ndern -- 3.1 Planung -- 3.2 Wertsch{\"o}pfungsstrukturen -- 3.3 Umsetzungsbeispiele -- 3.4 Multi-modale Mensch-Maschine-Schnittstelle -- 4 Warum Echtzeitn{\"a}he und XaaS der Schl{\"u}ssel f{\"u}r das neue Produktions-Paradigma sind -- 4.1 Die vier Lebenszyklen der Produktion -- 4.2 Von der Automatisierungspyramide zum service-orientier-ten Netz -- 4.3 Virtual Fort Knox -- 4.4 Zwischenfazit



5 Wie die marktgetriebene Migration in die Vierte Industrielle Revolution erfolgreich sein kann -- 5.1 Absch{\"a}tzung der Kostenpotenziale -- 5.2 Wie sollten Unternehmen vorgehen? -- 6 Fazit -- 7 Literatur -- 2 Herausforderungen und Anforderungen aus Sicht der IT und der Automatisierungstechnik -- 1 Einf{\"u}hrung -- 2 Was erm{\"o}glichen CPS f{\"u}r Industrie 4.0? -- 3 Was m{\"u}ssen CPS f{\"u}r Industrie 4.0 k{\"o}nnen? -- 3.1 Architekturmodelle (Referenzarchitektur) -- 3.2 Kommunikation und Datendurchg{\"a}ngigkeit -- 3.3 Intelligente Produkte und adaptive intelligente Produktions-einheiten



3.4 Informationsaggregation und -aufbereitung f{\"u}r den Men-schen -- 4 Literatur -- 3 Use Case Industrie 4.0-Fertigung im Siemens Elektronikwerk Amberg -- 1 Das Elektronikwerk Amberg (EWA) -- 1.1 Vision und Strategie -- 1.2 L{\"o}sungsans{\"a}tze aus Industrie 4.0 f{\"u}r unsere Herausforde-rungen -- 1.3 Der Mensch ist das Ma{\ss} aller Dinge (Protagoras) -- 1.4 Quality first -- 2 Produktionsautomatisierung 2.1 Der Startpunkt der Automatisierung -- 2.2 Die vertikale Integration -- 2.3 Die durchgehende Codierung und Identifizierung -- 2.4 Autonomiebewegung beim Produkt



2.5 Losgr{\"o}{\ss}e 1 ist bei Industrie 4.0 enthalten -- 3 Mensch-Maschine-Interaktion -- 3.1 Alle Maschinen online mit EWA-KommunikationsstandardComesco -- 3.2 Augmented Reality, Suchen und Zuordnen ist Vergangenheit -- 4 Der automatisierte Informationsfluss am Arbeitsplatz in der Produktion -- 5 DataMining -- 5.1 Automatisierte Auswertung der laufenden Prozessdaten, das Watchdog-Prinzip -- 5.2 Mit der Maus in die Tiefe, das Drill-Down-Prinzip -- 5.3 L{\"u}ckenlose Auswertung aller Prozessparameter, das Prin-zip Objektidentifikation -- 6 Lessons Learned, wir machen weiter



4 Enabling Industrie 4.0 - Chancen und Nutzen f{\"u}r die Prozess-industrie},
 author = {Vogel-Heuser, Birgit},
 year = {2016},
 title = {Handbuch Industrie 4.0 Bd.4: Allgemeine Grundlagen},
 url = {http://gbv.eblib.com/patron/FullRecord.aspx?p=4748961},
 price = {27.26 (NL),27.26 (1U)},
 address = {Berlin, Heidelberg},
 edition = {2nd ed.},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {9783662532546},
 series = {VDI Springer Reference},
 file = {Vogel-Heuser 2016 - Handbuch Industrie 40 Bd4:Attachments/Vogel-Heuser 2016 - Handbuch Industrie 40 Bd4.pdf:application/pdf}
}


@book{Vullo,
 abstract = {Gears: general concepts, definitions and basic quantities -- The geometry of involute spur gears -- Quantities of cylindrical spur gear and their determination -- Interference between external spur gears -- Interference between internal spur gears -- Profile shift of spur gear involute toothing -- Cylindrical involute helical gears -- Straight bevel gear -- Crossed helical gear -- Worm gears -- Spiral bevel and hypoid gears -- Gear trains and planetary gears -- Face gear pair.



The book explores the geometric and kinematic design of the various types of gears most commonly used in practical applications, also considering the problems concerning their cutting processes. The cylindrical spur and helical gears are first considered, determining their main geometric quantities in the light of interference and undercut problems, as well as the related kinematic parameters. Particular attention is paid to the profile shift of these types of gears either generated by rack-type cutter or by pinion-rack cutter. Among other things, profile-shifted toothing allows to obtain teeth shapes capable of greater strength and more balanced specific sliding, as well as to reduce the number of teeth below the minimum one to avoid the operating interference or undercut. These very important aspects of geometric-kinematic design of cylindrical spur and helical gears are then generalized and extended to the other examined types of gears most commonly used in practical applications, such as: straight bevel gears; crossed helical gears; worm gears; spiral bevel and hypoid gears. Finally, ordinary gear trains, planetary gear trains and face gear drives are discussed. Includes fully-developed exercises to draw the reader's attention to the problems that are of interest to the designer, as well as to clarify the calculation procedure Topics are addressed from a theoretical standpoint, but in such a way as not to lose sight of the physical phenomena that characterize the various types of gears which are examined The analytical and numerical solutions are formulated so as to be of interest not only to academics, but also to designers who deal with actual engineering problems concerning the gears.},
 author = {Vullo, Vincenzo},
 year = {2020},
 title = {Gears: Volume 1: Geometric and Kinematic Design},
 keywords = {Geometry;Machinery;Mechanics;Mechanics, Applied},
 address = {Cham},
 edition = {1st ed. 2020},
 volume = {10},
 publisher = {{Springer International Publishing} and {Imprint Springer}},
 isbn = {9783030365028},
 series = {Springer Series in Solid and Structural Mechanics},
 doi = {10.1007/978-3-030-36502-8},
 file = {Vullo 2020 - Gears:Attachments/Vullo 2020 - Gears.pdf:application/pdf}
}


@article{Wang,
 author = {Wang, Dong and Tsui, Kwok-Leung and Miao, Qiang},
 year = {2018},
 title = {Prognostics and Health Management: A Review of Vibration Based Bearing and Gear Health Indicators},
 pages = {665--676},
 volume = {6},
 issn = {2169-3536},
 journal = {IEEE Access},
 doi = {10.1109/access.2017.2774261}
}


@book{Wen,
 abstract = {Deep learning performs remarkably well on many time series analysis tasksrecently. The superior performance of deep neural networks relies heavily on alarge number of training data to avoid overfitting. However, the labeled dataof many real-world time series applications may be limited such asclassification in medical time series and anomaly detection in AIOps. As aneffective way to enhance the size and quality of the training data, dataaugmentation is crucial to the successful application of deep learning modelson time series data. In this paper, we systematically review different dataaugmentation methods for time series. We propose a taxonomy for the reviewedmethods, and then provide a structured review for these methods by highlightingtheir strengths and limitations. We also empirically compare different dataaugmentation methods for different tasks including time series classification,anomaly detection, and forecasting. Finally, we discuss and highlight fivefuture directions to provide useful research guidance.},
 author = {Wen, Qingsong and Sun, Liang and Yang, Fan and Song, Xiaomin and Gao, Jingkun and Wang, Xue and Xu, Huan},
 year = {2022},
 title = {Time Series Data Augmentation for Deep Learning: A Survey},
 doi = {10.24963/ijcai.2021/631},
 file = {Wen, Sun et al. 2022 - Time Series Data Augmentation:Attachments/Wen, Sun et al. 2022 - Time Series Data Augmentation.pdf:application/pdf}
}


@article{Werner,
 abstract = {Abstract Bei der betriebsfesten Auslegung von Bauteilen mit Hilfe der Schadensakkumulation spielt die Schadenssumme D eine gro{\ss}e Rolle. Wird f{\"u}r die Schadenssumme der theoretische Wert D = 1 angeno...},
 author = {Werner, S. and Bacher-H{\"o}chst, M. and Sonsino, C. M.},
 year = {2000},
 title = {Stabilit{\"a}t der tats{\"a}chlichen Schadenssumme gegen eine Variation des Kollektivumfangs, der Kerbsch{\"a}rfe und des Kollektivh{\"o}chstwertes am Beispiel der warmausgeh{\"a}rteten Knetlegierung AlMgSi1},
 pages = {589--597},
 volume = {31},
 number = {7},
 issn = {0933-5137},
 journal = {Materialwissenschaft und Werkstofftechnik},
 doi = {10.1002/1521-4052(200007)31:7{\textless}589::AID-MAWE589{\textgreater}3.0.CO;2-L}
}


@book{Will,
 author = {{Will Koehrsen}},
 year = {2018},
 title = {Overfitting vs. underfitting: A complete example},
 url = {http://www.pstu.ac.bd/files/materials/1566949131.pdf},
 file = {Will Koehrsen 2018 - Overfitting vs:Attachments/Will Koehrsen 2018 - Overfitting vs.pdf:application/pdf}
}


@book{Wittel,
 author = {Wittel, Herbert and Jannasch, Dieter and Vo{\ss}iek, Joachim and Spura, Christian},
 year = {2017},
 title = {Maschinenelemente},
 address = {Wiesbaden and Heidelberg},
 edition = {23., {\"u}berarbeitete und erweiterte Auflage},
 publisher = {{Springer Vieweg}},
 isbn = {9783658178956},
 doi = {10.1007/978-3-658-17896-3},
 file = {Wittel, Jannasch et al 2017 - Maschinenelemente:Attachments/Wittel, Jannasch et al 2017 - Maschinenelemente.pdf:application/pdf}
}


@book{Wittel.2021,
 author = {Wittel, Herbert and Spura, Christian and Jannasch, Dieter},
 year = {2021},
 title = {Roloff/Matek Maschinenelemente},
 address = {Wiesbaden},
 edition = {25. Auflage},
 publisher = {{Springer Vieweg}},
 isbn = {9783658341596},
 institution = {{Springer Fachmedien Wiesbaden}},
 file = {Wittel, Spura et al 2021 - Roloff Matek Maschinenelemente:Attachments/Wittel, Spura et al 2021 - Roloff Matek Maschinenelemente.pdf:application/pdf}
}


@book{Wohler,
 author = {W{\"o}hler, Alfred},
 year = {1870},
 title = {{\"U}ber die Festigkeitsversuche mit Eisen und Stahl},
 publisher = {{Ernst {\&} Korn}}
}


@article{Wuest,
 author = {Wuest, Thorsten and Weimer, Daniel and Irgens, Christopher and Thoben, Klaus-Dieter},
 year = {2016},
 title = {Machine learning in manufacturing: advantages, challenges, and applications},
 pages = {23--45},
 volume = {4},
 number = {1},
 journal = {Production {\&} Manufacturing Research},
 doi = {10.1080/21693277.2016.1192517},
 file = {Wuest, Weimer et al 2016 - Machine learning in manufacturing:Attachments/Wuest, Weimer et al 2016 - Machine learning in manufacturing.pdf:application/pdf}
}


@misc{XG,
 author = {XGBoost},
 year = {2023},
 title = {XGBoost Documentation --- xgboost 1.7.6 documentation (Access Date: 02/07/2023)},
 url = {https://xgboost.readthedocs.io/en/stable/}
}


@book{Xiaogang,
 author = {{Xiaogang Wang, Z Lei, X Zhang, B Zhou, J Peng}},
 year = {2016},
 title = {Machine learning basics: Deep learning},
 url = {http://whdeng.cn/teaching/ppt_01_machine%20learning%20basics.pdf},
 file = {Machine learning basics 2016 (2):Attachments/Machine learning basics 2016 (2).pdf:application/pdf}
}


@article{Yaguo,
 abstract = {Intelligent fault diagnosis (IFD) refers to applications of machine learning theories to machine fault diagnosis. This is a promising way to release the contribution from human labor and automatically recognize the health states of machines, thus it has attracted much attention in the last two or three decades. Although IFD has achieved a considerable number of successes, a review still leaves a blank space to systematically cover the development of IFD from the cradle to the bloom, and rarely provides potential guidelines for the future development. To bridge the gap, this article presents a review and roadmap to systematically cover the development of IFD following the progress of machine learning theories and offer a future perspective. In the past, traditional machine learning theories began to weak the contribution of human labor and brought the era of artificial intelligence to machine fault diagnosis. Over the recent years, the advent of deep learning theories has reformed IFD in further releasing the artificial assistance since the 2010s, which encourages to construct an end-to-end diagnosis procedure. It means to directly bridge the relationship between the increasingly-grown monitoring data and the health states of machines. In the future, transfer learning theories attempt to use the diagnosis knowledge from one or multiple diagnosis tasks to other related ones, which prospectively overcomes the obstacles in applications of IFD to engineering scenarios. Finally, the roadmap of IFD is pictured to show potential research trends when combined with the challenges in this field.},
 author = {{Yaguo Lei} and {Bin Yang} and {Xinwei Jiang} and {Feng Jia} and {Naipeng Li} and {Asoke K. Nandi}},
 year = {2020},
 title = {Applications of machine learning to machine fault diagnosis: A review and roadmap},
 url = {https://www.sciencedirect.com/science/article/pii/S0888327019308088},
 keywords = {Deep Learning;Intelligent fault diagnosis;Machine learning;Machines;Review;roadmap;Transfer learning},
 pages = {106587},
 volume = {138},
 issn = {0888-3270},
 journal = {Mechanical Systems and Signal Processing},
 doi = {10.1016/j.ymssp.2019.106587}
}


@article{Yan,
 author = {Yan, Haoran and Qin, Yi and Xiang, Sheng and Wang, Yi and Chen, Haizhou},
 year = {2020},
 title = {Long-term gear life prediction based on ordered neurons LSTM neural networks},
 url = {https://www.sciencedirect.com/science/article/pii/s0263224120307430},
 pages = {108205},
 volume = {165},
 issn = {0263-2241},
 journal = {Measurement},
 doi = {10.1016/j.measurement.2020.108205}
}


@inproceedings{Yang,
 author = {Yang, Jiawei and Rahardja, Susanto and Fr{\"a}nti, Pasi},
 title = {Outlier detection},
 publisher = {ACM},
 booktitle = {Proceedings of the International Conference on Artificial Intelligence, Information Processing and Cloud Computing},
 year = {2019},
 address = {New York, NY, USA},
 doi = {10.1145/3371425.3371427},
 file = {Yang, Rahardja et al. 2019 - Outlier detection:Attachments/Yang, Rahardja et al. 2019 - Outlier detection.pdf:application/pdf}
}


@article{Yang2,
 author = {Yang, Li and Shami, Abdallah},
 year = {2020},
 title = {On hyperparameter optimization of machine learning algorithms: Theory and practice},
 url = {https://www.sciencedirect.com/science/article/pii/s0925231220311693},
 pages = {295--316},
 volume = {415},
 issn = {0925-2312},
 journal = {Neurocomputing},
 doi = {10.1016/j.neucom.2020.07.061},
 file = {Yang, Shami 2020 - On hyperparameter optimization of machine:Attachments/Yang, Shami 2020 - On hyperparameter optimization of machine.pdf:application/pdf}
}


@book{Yoshua,
 author = {{Yoshua Bengio , Yves Grandvalet}},
 year = {2003},
 title = {No unbiased estimator of the variance of k-fold cross-validation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2003/file/e82c4b19b8151ddc25d4d93baf7b908f-Paper.pdf},
 publisher = {{MIT Press}},
 file = {No unbiased estimator 2003:Attachments/No unbiased estimator 2003.pdf:application/pdf}
}


@article{Yuksel,
 author = {Yuksel, C. and Kahraman, A.},
 year = {2004},
 title = {Dynamic tooth loads of planetary gear sets having tooth profile wear},
 url = {https://www.sciencedirect.com/science/article/pii/s0094114x04000448},
 pages = {695--715},
 volume = {39},
 number = {7},
 issn = {0094-114X},
 journal = {Mechanism and Machine Theory},
 doi = {10.1016/j.mechmachtheory.2004.03.001},
 file = {Yuksel, Kahraman 2004 - Dynamic tooth loads of planetary:Attachments/Yuksel, Kahraman 2004 - Dynamic tooth loads of planetary.pdf:application/pdf}
}


@article{Zhang,
 author = {Zhang, Xinyu and Liu, Chu-An},
 year = {2023},
 title = {Model averaging prediction by K -fold cross-validation},
 url = {https://www.sciencedirect.com/science/article/pii/s0304407622000975},
 pages = {280--301},
 volume = {235},
 number = {1},
 issn = {0304-4076},
 journal = {Journal of Econometrics},
 doi = {10.1016/j.jeconom.2022.04.007}
}


@book{Zhangpiml,
 abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training.  Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice.  We interpret our experimental findings by comparison with traditional models.},
 author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
 year = {2017},
 title = {Understanding deep learning requires rethinking generalization},
 url = {https://arxiv.org/pdf/1611.03530},
 doi = {ICLR},
 file = {Zhang, Bengio et al 2016 - Understanding deep learning requires rethinking:Attachments/Zhang, Bengio et al 2016 - Understanding deep learning requires rethinking.pdf:application/pdf}
}


@book{Zhao,
 author = {Zhao, Rui and Wang, Jinjiang and Yan, Ruqiang and Mao, Kezhi},
 year = {2016},
 title = {Machine health monitoring with LSTM networks},
 doi = {10.1109/icsenst.2016.7796266},
 file = {Zhao, Wang et al. 2016 - Machine health monitoring with LSTM:Attachments/Zhao, Wang et al. 2016 - Machine health monitoring with LSTM.pdf:application/pdf}
}


@article{Zhu,
 abstract = {We review some of the literature on semi-supervised learning in this paper. Traditional classifiers need labeled data (feature / label pairs) to train. Labeled instances however are often difficult, expensive, or time consuming to obtain, as they require the efforts of experienced human annotators. Meanwhile unlabeled data may be relatively easy to collect, but there has been few ways to use them. Semi-supervised learning addresses this problem by using large amount of unlabeled data, together with the labeled data, to build better classifiers. Because semi-supervised learning requires less human effort and gives higher

accuracy, it is of great interest both in theory and in practice.},
 author = {Zhu, Xiaojin},
 year = {2005},
 title = {Semi-Supervised Learning Literature Survey},
 url = {https://minds.wisconsin.edu/handle/1793/60444},
 file = {Zhu - Semi-Supervised Learning Literature Survey:Attachments/Zhu - Semi-Supervised Learning Literature Survey.pdf:application/pdf}
}


@article{Zhu1,
 author = {Zhu, Shun-Peng and Liao, Ding and Liu, Qiang and Correia, Jos{\'e} A.F.O. and de Jesus, Ab{\'i}lio M.P.},
 year = {2019},
 title = {Nonlinear fatigue damage accumulation: Isodamage curve-based model and life prediction aspects},
 url = {https://www.sciencedirect.com/science/article/pii/s0142112319302750},
 pages = {105185},
 volume = {128},
 issn = {0142-1123},
 journal = {International Journal of Fatigue},
 doi = {10.1016/j.ijfatigue.2019.105185}
}


@article{Zuo,
 author = {Zuo, Fang-Jun and Huang, Hong-Zhong and Zhu, Shun-Peng and Lv, Zhiqiang and Gao, Huiying},
 year = {2015},
 title = {Fatigue life prediction under variable amplitude loading using a non-linear damage accumulation model},
 pages = {767--784},
 volume = {24},
 number = {5},
 issn = {1056-7895},
 journal = {International Journal of Damage Mechanics},
 doi = {10.1177/1056789514553042}
}


